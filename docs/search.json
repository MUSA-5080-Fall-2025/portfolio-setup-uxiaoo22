[
  {
    "objectID": "instructions_week1.html",
    "href": "instructions_week1.html",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "Welcome to MUSA 5080! This guide will help you set up your personal portfolio repository for the semester.\n\n\nBy the end of this setup, you’ll have: - Your own portfolio repository on GitHub - live website showcasing your work - A place to document your learning journey\n\n\n\n\nThis is what you are building: Dr. Delmelle’s sample portfolio\n\n\n\n\nBefore starting, make sure you have: - [ ] A GitHub account (create one here if needed) - [ ] Quarto installed on your computer (download here) - [ ] R and RStudio installed\n\n\n\n\n\nYou should already be in your personal repository (created when you accepted the GitHub Classroom assignment). Now let’s personalize it!\n\n\n\nClick on the _quarto.yml file\nClick the pencil icon (✏️) to edit\nChange \"Your Name - MUSA 5080 Portfolio\" to include your actual name\nExample: \"Jane Smith - MUSA 5080 Portfolio\"\nClick “Commit changes” at the bottom\n\n\n\n\n\nClick on the index.qmd file\nClick the pencil icon (✏️) to edit\nUpdate the “About Me” section with your information:\n\nYour name and background\nYour email address\nYour GitHub username\nWhy you’re taking this course\n\nClick “Commit changes”\n\n\n\n\n\nNavigate to the weekly-notes folder\nClick on week-01-notes.qmd\nClick the pencil icon (✏️) to edit\nFill in your notes from the first class\nClick “Commit changes”\n\n\n\n\n\nThis step makes your portfolio visible as a live website!\n\nGo to Settings: Click the “Settings” tab at the top of your repository\nFind Pages: Scroll down and click “Pages” in the left sidebar\nConfigure Source:\n\nSource: Select “Deploy from a branch”\nBranch: Select “main”\nFolder: Select “/ docs”\n\nSave: Click “Save”\nWait: GitHub will show a message that your site is being built (this takes 1-5 minutes)\n\n\n\n\n\nFind Your URL: After a few minutes, GitHub will show your website URL at the top of the Pages settings\n\nIt will look like: https://yourusername.github.io/repository-name\n\nVisit Your Site: Click the link to see your live portfolio!\nBookmark It: Save this URL - you’ll submit it to Canvas\n\n\n\n\n\nCopy your live website URL\nGo to the Canvas assignment\nSubmit your URL\n\n\n\n\n\nIf you want to work on your computer and see changes before publishing:\n\n\n# Replace [your-repo-url] with your actual repository URL\ngit clone [your-repo-url]\ncd [your-repository-name]\n\n\n\n# Edit your files using RStudio\n# Preview your changes:\nquarto render\nquarto preview\n\n# When ready, save your changes:\ngit add .\ngit commit -m \"Update portfolio\"\ngit push\nYour live website will automatically update when you push changes!\n\n\n\n\nEach week you’ll: 1. Create a new file: weekly-notes/week-XX-notes.qmd 2. Copy the template from week-01-notes.qmd 3. Fill in your reflections and key concepts 4. Commit and push your changes\n\n\n\n\n\n\nWait longer: GitHub Pages can take up to 10 minutes to build\nCheck Actions tab: Look for any red X marks indicating build failures\nVerify Pages settings: Make sure you selected “main” branch and “/docs” folder\n\n\n\n\n\nCheck permissions: Make sure you’re in YOUR repository, not the template\nSign in: Ensure you’re signed into GitHub\n\n\n\n\n\nCheck YAML syntax: Make sure your _quarto.yml file has proper formatting\nVerify file names: Files should end in .qmd not .md\nLook at error messages: The Actions tab will show specific error details\n\n\n\n\n\nDon’t panic! Every change is tracked in Git\nSee history: Click the “History” button on any file to see previous versions\nRevert changes: You can always go back to a previous version\n\n\n\n\n\n\nCommit often: Save your work frequently with descriptive commit messages\nUse branches: For major changes, create a new branch and merge when ready\nPreview locally: Use quarto preview to see changes before publishing\nKeep it professional: This portfolio can be shared with future employers!\nDocument everything: Good documentation is as important as good analysis\n\n\n\n\n\nQuarto Documentation\nGitHub Docs\nMarkdown Guide\nGit Tutorial\n\n\n\n\nDuring Class: - Raise your hand for immediate help - Work with classmates - collaboration is encouraged for setup!\nOutside Class: - Office Hours: Mondays 1:30-3:00 PM - Email: delmelle@design.upenn.edu - GitHub Issues: Create an issue in your repository for technical problems - Canvas Discussion: Post questions others might have too\n\n\n\nBefore submitting, make sure you’ve: - [ ] Customized _quarto.yml with your name - [ ] Updated index.qmd with your information - [ ] Completed Week 1 notes - [ ] Enabled GitHub Pages - [ ] Verified your website loads correctly - [ ] Submitted your URL to Canvas\n\nNeed help? Don’t struggle alone - reach out during office hours (mine + TAs) or in class!"
  },
  {
    "objectID": "instructions_week1.html#what-youre-building",
    "href": "instructions_week1.html#what-youre-building",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "By the end of this setup, you’ll have: - Your own portfolio repository on GitHub - live website showcasing your work - A place to document your learning journey"
  },
  {
    "objectID": "instructions_week1.html#example",
    "href": "instructions_week1.html#example",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "This is what you are building: Dr. Delmelle’s sample portfolio"
  },
  {
    "objectID": "instructions_week1.html#prerequisites",
    "href": "instructions_week1.html#prerequisites",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "Before starting, make sure you have: - [ ] A GitHub account (create one here if needed) - [ ] Quarto installed on your computer (download here) - [ ] R and RStudio installed"
  },
  {
    "objectID": "instructions_week1.html#step-by-step-setup",
    "href": "instructions_week1.html#step-by-step-setup",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "You should already be in your personal repository (created when you accepted the GitHub Classroom assignment). Now let’s personalize it!\n\n\n\nClick on the _quarto.yml file\nClick the pencil icon (✏️) to edit\nChange \"Your Name - MUSA 5080 Portfolio\" to include your actual name\nExample: \"Jane Smith - MUSA 5080 Portfolio\"\nClick “Commit changes” at the bottom\n\n\n\n\n\nClick on the index.qmd file\nClick the pencil icon (✏️) to edit\nUpdate the “About Me” section with your information:\n\nYour name and background\nYour email address\nYour GitHub username\nWhy you’re taking this course\n\nClick “Commit changes”\n\n\n\n\n\nNavigate to the weekly-notes folder\nClick on week-01-notes.qmd\nClick the pencil icon (✏️) to edit\nFill in your notes from the first class\nClick “Commit changes”\n\n\n\n\n\nThis step makes your portfolio visible as a live website!\n\nGo to Settings: Click the “Settings” tab at the top of your repository\nFind Pages: Scroll down and click “Pages” in the left sidebar\nConfigure Source:\n\nSource: Select “Deploy from a branch”\nBranch: Select “main”\nFolder: Select “/ docs”\n\nSave: Click “Save”\nWait: GitHub will show a message that your site is being built (this takes 1-5 minutes)\n\n\n\n\n\nFind Your URL: After a few minutes, GitHub will show your website URL at the top of the Pages settings\n\nIt will look like: https://yourusername.github.io/repository-name\n\nVisit Your Site: Click the link to see your live portfolio!\nBookmark It: Save this URL - you’ll submit it to Canvas\n\n\n\n\n\nCopy your live website URL\nGo to the Canvas assignment\nSubmit your URL"
  },
  {
    "objectID": "instructions_week1.html#working-on-your-portfolio-locally-optional-but-recommended",
    "href": "instructions_week1.html#working-on-your-portfolio-locally-optional-but-recommended",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "If you want to work on your computer and see changes before publishing:\n\n\n# Replace [your-repo-url] with your actual repository URL\ngit clone [your-repo-url]\ncd [your-repository-name]\n\n\n\n# Edit your files using RStudio\n# Preview your changes:\nquarto render\nquarto preview\n\n# When ready, save your changes:\ngit add .\ngit commit -m \"Update portfolio\"\ngit push\nYour live website will automatically update when you push changes!"
  },
  {
    "objectID": "instructions_week1.html#weekly-workflow",
    "href": "instructions_week1.html#weekly-workflow",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "Each week you’ll: 1. Create a new file: weekly-notes/week-XX-notes.qmd 2. Copy the template from week-01-notes.qmd 3. Fill in your reflections and key concepts 4. Commit and push your changes"
  },
  {
    "objectID": "instructions_week1.html#troubleshooting",
    "href": "instructions_week1.html#troubleshooting",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "Wait longer: GitHub Pages can take up to 10 minutes to build\nCheck Actions tab: Look for any red X marks indicating build failures\nVerify Pages settings: Make sure you selected “main” branch and “/docs” folder\n\n\n\n\n\nCheck permissions: Make sure you’re in YOUR repository, not the template\nSign in: Ensure you’re signed into GitHub\n\n\n\n\n\nCheck YAML syntax: Make sure your _quarto.yml file has proper formatting\nVerify file names: Files should end in .qmd not .md\nLook at error messages: The Actions tab will show specific error details\n\n\n\n\n\nDon’t panic! Every change is tracked in Git\nSee history: Click the “History” button on any file to see previous versions\nRevert changes: You can always go back to a previous version"
  },
  {
    "objectID": "instructions_week1.html#pro-tips",
    "href": "instructions_week1.html#pro-tips",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "Commit often: Save your work frequently with descriptive commit messages\nUse branches: For major changes, create a new branch and merge when ready\nPreview locally: Use quarto preview to see changes before publishing\nKeep it professional: This portfolio can be shared with future employers!\nDocument everything: Good documentation is as important as good analysis"
  },
  {
    "objectID": "instructions_week1.html#additional-resources",
    "href": "instructions_week1.html#additional-resources",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "Quarto Documentation\nGitHub Docs\nMarkdown Guide\nGit Tutorial"
  },
  {
    "objectID": "instructions_week1.html#getting-help",
    "href": "instructions_week1.html#getting-help",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "During Class: - Raise your hand for immediate help - Work with classmates - collaboration is encouraged for setup!\nOutside Class: - Office Hours: Mondays 1:30-3:00 PM - Email: delmelle@design.upenn.edu - GitHub Issues: Create an issue in your repository for technical problems - Canvas Discussion: Post questions others might have too"
  },
  {
    "objectID": "instructions_week1.html#checklist",
    "href": "instructions_week1.html#checklist",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "Before submitting, make sure you’ve: - [ ] Customized _quarto.yml with your name - [ ] Updated index.qmd with your information - [ ] Completed Week 1 notes - [ ] Enabled GitHub Pages - [ ] Verified your website loads correctly - [ ] Submitted your URL to Canvas\n\nNeed help? Don’t struggle alone - reach out during office hours (mine + TAs) or in class!"
  },
  {
    "objectID": "weekly-notes/week-02-notes.html",
    "href": "weekly-notes/week-02-notes.html",
    "title": "Week 2 Notes",
    "section": "",
    "text": "[List main concepts from lecture] Repository (repo): Folder containing your project files Commit: Snapshot of your work at a point in time Push: Send your changes to GitHub cloud Pull: Get latest changes from GitHub cloud\n[Technical skills covered]"
  },
  {
    "objectID": "weekly-notes/week-02-notes.html#key-concepts-learned",
    "href": "weekly-notes/week-02-notes.html#key-concepts-learned",
    "title": "Week 2 Notes",
    "section": "",
    "text": "[List main concepts from lecture] Repository (repo): Folder containing your project files Commit: Snapshot of your work at a point in time Push: Send your changes to GitHub cloud Pull: Get latest changes from GitHub cloud\n[Technical skills covered]"
  },
  {
    "objectID": "weekly-notes/week-02-notes.html#coding-techniques",
    "href": "weekly-notes/week-02-notes.html#coding-techniques",
    "title": "Week 2 Notes",
    "section": "Coding Techniques",
    "text": "Coding Techniques\n\n[New R functions or approaches] Powerful for spatial analysis and policy-focused statistics\n[Quarto features learned] Quarto is the “next generation” Better website creation Works with multiple programming languages Same basic concept, improved features"
  },
  {
    "objectID": "weekly-notes/week-02-notes.html#questions-challenges",
    "href": "weekly-notes/week-02-notes.html#questions-challenges",
    "title": "Week 2 Notes",
    "section": "Questions & Challenges",
    "text": "Questions & Challenges\n\n[What I didn’t fully understand]\n[Areas needing more practice]"
  },
  {
    "objectID": "weekly-notes/week-02-notes.html#connections-to-policy",
    "href": "weekly-notes/week-02-notes.html#connections-to-policy",
    "title": "Week 2 Notes",
    "section": "Connections to Policy",
    "text": "Connections to Policy\n\n[How this week’s content applies to real policy work] Free and open source Excellent for spatial data Strong statistical capabilities Large community in urban planning/policy Reproducible research workflows"
  },
  {
    "objectID": "weekly-notes/week-02-notes.html#reflection",
    "href": "weekly-notes/week-02-notes.html#reflection",
    "title": "Week 2 Notes",
    "section": "Reflection",
    "text": "Reflection\n\n[What was most interesting]\n[How I’ll apply this knowledge]"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "This portfolio documents my learning journey in Public Policy Analytics (MUSA 5080).\n\n\nAdvanced spatial analysis and data science for urban planning and public policy.\n\n\n\n\nWeekly Notes: My learning reflections and key concepts\nLabs: Completed assignments and analyses\nFinal Project: Capstone modeling challenge\n\n\n\n\n\nMy name is Xiao Yu, you can call me Cathy. I am a MUSA student. I completed my undergraduate degree in Urban Studies and Planning at the University of Sheffield.\n\n\n\n\n\nEmail: [uxiaoo22@upenn.edu]\nGitHub: [@uxiaoo22]"
  },
  {
    "objectID": "index.html#about-this-course",
    "href": "index.html#about-this-course",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "Advanced spatial analysis and data science for urban planning and public policy."
  },
  {
    "objectID": "index.html#portfolio-structure",
    "href": "index.html#portfolio-structure",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "Weekly Notes: My learning reflections and key concepts\nLabs: Completed assignments and analyses\nFinal Project: Capstone modeling challenge"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "My name is Xiao Yu, you can call me Cathy. I am a MUSA student. I completed my undergraduate degree in Urban Studies and Planning at the University of Sheffield."
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "Email: [uxiaoo22@upenn.edu]\nGitHub: [@uxiaoo22]"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment_1.html",
    "href": "Assignments /Assignment_1/Assignment_1.html",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the Texas Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.\n\n\n\n\nApply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders\n\n\n\n\nSubmit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Assignments” menu."
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment_1.html#scenario",
    "href": "Assignments /Assignment_1/Assignment_1.html#scenario",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the Texas Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues."
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment_1.html#learning-objectives",
    "href": "Assignments /Assignment_1/Assignment_1.html#learning-objectives",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Apply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment_1.html#submission-instructions",
    "href": "Assignments /Assignment_1/Assignment_1.html#submission-instructions",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Submit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Assignments” menu."
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment_1.html#data-retrieval",
    "href": "Assignments /Assignment_1/Assignment_1.html#data-retrieval",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.1 Data Retrieval",
    "text": "2.1 Data Retrieval\nYour Task: Use get_acs() to retrieve county-level data for your chosen state.\nRequirements: - Geography: county level - Variables: median household income (B19013_001) and total population (B01003_001)\n- Year: 2022 - Survey: acs5 - Output format: wide\nHint: Remember to give your variables descriptive names using the variables = c(name = \"code\") syntax.\n\n# Write your get_acs() code here\ncounty_data_2022 &lt;- get_acs(\n  geography = \"county\",\n  variables = c(\n    total_pop = \"B01003_001\",       # Total population\n    med_household_income = \"B19013_001\"   # Median household income\n    ),\n  state = \"TX\",\n  year = 2022,\n  output = \"wide\"\n)\n# Clean the county names to remove state name and \"County\" \ncounty_data_2022 &lt;- county_data_2022 %&gt;%\n  mutate(county_name = str_remove(NAME, \", Texas\"))\n\n# Display the first few rows\nhead(county_data_2022)\n\n# A tibble: 6 × 7\n  GEOID NAME   total_popE total_popM med_household_incomeE med_household_incomeM\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;                 &lt;dbl&gt;                 &lt;dbl&gt;\n1 48001 Ander…      58077         NA                 57445                  4562\n2 48003 Andre…      18362         NA                 86458                 16116\n3 48005 Angel…      86608         NA                 57055                  2484\n4 48007 Arans…      24048         NA                 58168                  6458\n5 48009 Arche…       8649         NA                 69954                  8482\n6 48011 Armst…       1912        145                 70417                 14574\n# ℹ 1 more variable: county_name &lt;chr&gt;"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment_1.html#data-quality-assessment",
    "href": "Assignments /Assignment_1/Assignment_1.html#data-quality-assessment",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.2 Data Quality Assessment",
    "text": "2.2 Data Quality Assessment\nYour Task: Calculate margin of error percentages and create reliability categories.\nRequirements: - Calculate MOE percentage: (margin of error / estimate) * 100 - Create reliability categories: - High Confidence: MOE &lt; 5% - Moderate Confidence: MOE 5-10%\n- Low Confidence: MOE &gt; 10% - Create a flag for unreliable estimates (MOE &gt; 10%)\nHint: Use mutate() with case_when() for the categories.\n\nlibrary(scales)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# Calculate MOE percentage and reliability categories using mutate()\nTX_county_reliability &lt;- county_data_2022 %&gt;%\n  mutate(\n    med_income_moe_pct = (med_household_incomeM / med_household_incomeE) * 100,\n    med_income_confi = case_when(\n      med_income_moe_pct &lt; 5 ~ \"High Confidence (&lt;5%)\",\n      med_income_moe_pct &gt; 5 & med_income_moe_pct &lt;10 ~ \"Moderate Confidence (5% - 10%)\",\n      med_income_moe_pct &gt; 10  ~ \"Low Confidence (&gt;10%)\"\n ),\n    unreliable_income = med_income_moe_pct &gt;= 10\n  )\n# Create a summary showing count of counties in each reliability category\nTX_reliability_summary &lt;- TX_county_reliability %&gt;%\n  count(med_income_confi) %&gt;%\n  mutate(percent = round(100 * n / sum(n), 1))\n\n# Display the summary table\nkable(\n  TX_reliability_summary,\n  caption = \"Texas county-level median household income reliability (ACS 2022)\",\n  col.names = c(\"Reliability Category\", \"Count\", \"Percentage\"),\n  align = c(\"l\", \"r\", \"r\")\n) %&gt;%\n  kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n    full_width = FALSE,\n    position = \"center\"\n  )\n\n\n\nTexas county-level median household income reliability (ACS 2022)\n\n\nReliability Category\nCount\nPercentage\n\n\n\n\nHigh Confidence (&lt;5%)\n58\n22.8\n\n\nLow Confidence (&gt;10%)\n113\n44.5\n\n\nModerate Confidence (5% - 10%)\n82\n32.3\n\n\nNA\n1\n0.4\n\n\n\n\n\n# Hint: use count() and mutate() to add percentages"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment_1.html#high-uncertainty-counties",
    "href": "Assignments /Assignment_1/Assignment_1.html#high-uncertainty-counties",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.3 High Uncertainty Counties",
    "text": "2.3 High Uncertainty Counties\nYour Task: Identify the 5 counties with the highest MOE percentages.\nRequirements: - Sort by MOE percentage (highest first) - Select the top 5 counties - Display: county name, median income, margin of error, MOE percentage, reliability category - Format as a professional table using kable()\nHint: Use arrange(), slice(), and select() functions.\n\nlibrary(scales)\nlibrary(kableExtra)\n\n# Create table of top 5 counties by MOE percentage\nTX_high_uncertainty &lt;- TX_county_reliability %&gt;%\n  arrange(desc(med_income_moe_pct)) %&gt;%\n  slice(1:5) %&gt;%\n  select(\n    County = county_name,\n    `Median Income ($)` = med_household_incomeE,\n    `Margin of Error ($)` = med_household_incomeM,\n    `MOE (%)` = med_income_moe_pct,\n    Reliability = med_income_confi\n  ) %&gt;%\n  # Format numbers for professional output\n  mutate(\n    `Median Income ($)` = dollar(`Median Income ($)`),\n    `Margin of Error ($)` = dollar(`Margin of Error ($)`),\n    `MOE (%)` = paste0(round(`MOE (%)`, 1), \"%\")\n  )\n\n# Format as table with kable() - include appropriate column names and caption\nkable(\n  TX_high_uncertainty,\n  caption = \"Top 5 Texas Counties by Margin of Error in Median Household Income (ACS 2022)\",\n  align = c(\"l\", \"r\", \"r\", \"r\", \"l\")  # set column alignment\n) %&gt;%\n  kable_styling(full_width = FALSE, position = \"center\")\n\n\nTop 5 Texas Counties by Margin of Error in Median Household Income (ACS 2022)\n\n\nCounty\nMedian Income ($)\nMargin of Error ($)\nMOE (%)\nReliability\n\n\n\n\nJeff Davis County\n$38,125\n$25,205\n66.1%\nLow Confidence (&gt;10%)\n\n\nCulberson County\n$35,924\n$18,455\n51.4%\nLow Confidence (&gt;10%)\n\n\nKing County\n$59,375\n$29,395\n49.5%\nLow Confidence (&gt;10%)\n\n\nKinney County\n$52,386\n$23,728\n45.3%\nLow Confidence (&gt;10%)\n\n\nDimmit County\n$27,374\n$12,374\n45.2%\nLow Confidence (&gt;10%)\n\n\n\n\n\nData Quality Commentary:\nThe five Texas counties with the highest margins of error in median household income estimates—Jeff Davis, Culberson, King, Kinney, and Dimmit—show MOE percentages ranging from 45% to 66%. Such extreme levels indicate that ACS estimates for these areas are highly unreliable. The primary causes are small populations, limited survey samples, and income variability that magnifies error. If used directly in algorithmic decision-making, these data could misclassify community needs and distort funding priorities. Policymakers should instead supplement ACS data with administrative or tax records, or require manual review, to ensure fair and accurate resource allocation."
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment_1.html#focus-area-selection",
    "href": "Assignments /Assignment_1/Assignment_1.html#focus-area-selection",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.1 Focus Area Selection",
    "text": "3.1 Focus Area Selection\nYour Task: Select 2-3 counties from your reliability analysis for detailed tract-level study.\nStrategy: Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.\n\nlibrary(scales)\n\n# Use filter() to select 2-3 counties from your county_reliability data\n# Store the selected counties in a variable called selected_counties\nselected_counties &lt;- TX_county_reliability %&gt;%\n  filter(med_household_incomeE %in% c(35924, 27374)) %&gt;%\n  mutate(`MOE (%)` = round(med_income_moe_pct, 1)) %&gt;%\n  select(\n    County = county_name,\n    `Median Income ($)` = med_household_incomeE,\n    `MOE (%)`,\n    Reliability = med_income_confi\n  )\n# Display the selected counties with their key characteristics\n# Show: county name, median income, MOE percentage, reliability category\n# Display the selected counties\nkable(\n  selected_counties,\n  caption = \"Selected Texas Counties for Tract-Level Analysis\",\n  align = c(\"l\", \"r\", \"r\", \"r\", \"l\")\n) %&gt;%\n  kable_styling(full_width = FALSE, position = \"center\", bootstrap_options = c(\"striped\", \"hover\"))\n\n\nSelected Texas Counties for Tract-Level Analysis\n\n\nCounty\nMedian Income ($)\nMOE (%)\nReliability\n\n\n\n\nCulberson County\n35924\n51.4\nLow Confidence (&gt;10%)\n\n\nDimmit County\n27374\n45.2\nLow Confidence (&gt;10%)\n\n\n\n\n\nComment on the output:Culberson and Dimmit Counties were selected as examples of Low Confidence data. Their high MOE values reflect the challenges of using ACS estimates in small, rural counties."
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment_1.html#tract-level-demographics",
    "href": "Assignments /Assignment_1/Assignment_1.html#tract-level-demographics",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.2 Tract-Level Demographics",
    "text": "3.2 Tract-Level Demographics\nYour Task: Get demographic data for census tracts in your selected counties.\nRequirements: - Geography: tract level - Variables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001) - Use the same state and year as before - Output format: wide - Challenge: You’ll need county codes, not names. Look at the GEOID patterns in your county data for hints.\n\n# Define your race/ethnicity variables with descriptive names\nrace_vars &lt;- get_acs(\n  geography = \"tract\",\n  survey = \"acs5\",\n  variables = c(\n    white = \"B03002_003\", \n    black = \"B03002_004\",\n    hisp_latinx = \"B03002_012\",\n    total_pop = \"B03002_001\"\n  ),\n  year = 2022,\n  state = \"TX\",\n  county = c(\"109\", \"127\"),  # Culberson = 48109, Dimmit = 48127\n  output = \"wide\"\n)\n\n# Use get_acs() to retrieve tract-level data\n# Hint: You may need to specify county codes in the county parameter\n\n# Calculate percentage of each group using mutate()\n# Create percentages for white, Black, and Hispanic populations\nrace_vars &lt;- race_vars %&gt;%\n  mutate(\n    pct_white = 100 * whiteE / total_popE,\n    pct_black = 100 * blackE / total_popE,\n    pct_hispanic = 100 * hisp_latinxE / total_popE,\n    \n    # Split NAME on semicolon to extract tract and county\n    tract_name = sapply(strsplit(NAME, \";\"), function(x) trimws(x[1])),\n    county_name = sapply(strsplit(NAME, \";\"), function(x) trimws(x[2])) %&gt;%\n                  str_remove(\" County\")\n  )\n# Inspect first few rows\nhead(race_vars %&gt;%\n       select(tract_name, county_name, pct_white, pct_black, pct_hispanic))\n\n# A tibble: 4 × 5\n  tract_name           county_name pct_white pct_black pct_hispanic\n  &lt;chr&gt;                &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 Census Tract 9503    Culberson       11.4      0.183         81.3\n2 Census Tract 9502.01 Dimmit           7.39     0.242         91.7\n3 Census Tract 9502.02 Dimmit          17.2      1.56          77.2\n4 Census Tract 9504    Dimmit           4.20     0.156         93.8\n\n# Add readable tract and county name columns using str_extract() or similar"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment_1.html#demographic-analysis",
    "href": "Assignments /Assignment_1/Assignment_1.html#demographic-analysis",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.3 Demographic Analysis",
    "text": "3.3 Demographic Analysis\nYour Task: Analyze the demographic patterns in your selected areas.\n\nlibrary(dplyr)\nlibrary(knitr)\n# Find the tract with the highest percentage of Hispanic/Latino residents\n# Hint: use arrange() and slice() to get the top tract\ntop_hispanic_tract &lt;- race_vars %&gt;%\n  arrange(desc(pct_hispanic)) %&gt;%\n  slice(1) %&gt;%\n  transmute(\n    Tract = tract_name,\n    County = county_name,\n    `Hispanic %` = percent(pct_hispanic / 100, accuracy = 0.1)\n  )\n\nkable(top_hispanic_tract,\n      caption = \"Tract with Highest Hispanic/Latino Population\",\n      align = c(\"l\", \"l\", \"r\")) %&gt;%\n  kable_styling(full_width = FALSE, position = \"center\",\n                bootstrap_options = c(\"striped\", \"hover\"))\n\n\nTract with Highest Hispanic/Latino Population\n\n\nTract\nCounty\nHispanic %\n\n\n\n\nCensus Tract 9504\nDimmit\n93.8%\n\n\n\n\n# Calculate average demographics by county using group_by() and summarize()\n# Show: number of tracts, average percentage for each racial/ethnic group\ncounty_summary &lt;- race_vars %&gt;%\n  group_by(county_name) %&gt;%\n  summarise(\n    `Number of Tracts` = n(),\n    `Avg. White %` = percent(mean(pct_white, na.rm = TRUE) / 100, accuracy = 0.1),\n    `Avg. Black %` = percent(mean(pct_black, na.rm = TRUE) / 100, accuracy = 0.1),\n    `Avg. Hispanic %` = percent(mean(pct_hispanic, na.rm = TRUE) / 100, accuracy = 0.1)\n  )\n# Create a nicely formatted table of your results using kable()\nkable(\n  county_summary,\n  caption = \"Average Demographic Composition by County\",\n  align = c(\"l\", \"r\", \"r\", \"r\", \"r\")\n) %&gt;%\n  kable_styling(full_width = FALSE, position = \"center\",\n                bootstrap_options = c(\"striped\", \"hover\"))\n\n\nAverage Demographic Composition by County\n\n\ncounty_name\nNumber of Tracts\nAvg. White %\nAvg. Black %\nAvg. Hispanic %\n\n\n\n\nCulberson\n1\n11.4%\n0.2%\n81.3%\n\n\nDimmit\n3\n9.6%\n0.7%\n87.6%"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment_1.html#moe-analysis-for-demographic-variables",
    "href": "Assignments /Assignment_1/Assignment_1.html#moe-analysis-for-demographic-variables",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "4.1 MOE Analysis for Demographic Variables",
    "text": "4.1 MOE Analysis for Demographic Variables\nYour Task: Examine margins of error for demographic variables to see if some communities have less reliable data.\nRequirements: - Calculate MOE percentages for each demographic variable - Flag tracts where any demographic variable has MOE &gt; 15% - Create summary statistics\n\n# Calculate MOE percentages for white, Black, and Hispanic variables\n# Hint: use the same formula as before (margin/estimate * 100)\n# Create a flag for tracts with high MOE on any demographic variable\n# Use logical operators (| for OR) in an ifelse() statement\ndemo_moe &lt;- race_vars %&gt;%\n  mutate(\n    white_moe_pct = (whiteM / whiteE) * 100,\n    black_moe_pct = (blackM / blackE) * 100,\n    hispanic_moe_pct = (hisp_latinxM / hisp_latinxE) * 100,\n    \n    # Flag tracts where any demographic MOE &gt; 15%\n    high_moe_flag = ifelse(\n      white_moe_pct &gt; 15 | black_moe_pct &gt; 15 | hispanic_moe_pct &gt; 15,\n      TRUE, FALSE\n    )\n  )\n# Create summary statistics showing how many tracts have data quality issues\nmoe_summary_county &lt;- demo_moe %&gt;%\n  group_by(county_name) %&gt;%\n  summarise(\n    total_tracts = n(),\n    high_moe_tracts = sum(high_moe_flag, na.rm = TRUE),\n    percent_high_moe = round(100 * mean(high_moe_flag, na.rm = TRUE), 1)\n  )\n\nkable(\n  moe_summary_county,\n  caption = \"**MOE Summary by County (ACS 2022)**\",\n  row.names = FALSE,\n  col.names = c(\"County\", \"Total Tracts\", \"High MOE Tracts\", \"Percent High MOE (%)\"),\n  align = c(\"l\", \"c\", \"c\", \"r\")\n) %&gt;%\n  kable_styling(full_width = FALSE, position = \"center\",\n                bootstrap_options = c(\"striped\", \"hover\"))\n\n\n**MOE Summary by County (ACS 2022)**\n\n\nCounty\nTotal Tracts\nHigh MOE Tracts\nPercent High MOE (%)\n\n\n\n\nCulberson\n1\n1\n100\n\n\nDimmit\n3\n3\n100"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment_1.html#pattern-analysis",
    "href": "Assignments /Assignment_1/Assignment_1.html#pattern-analysis",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "4.2 Pattern Analysis",
    "text": "4.2 Pattern Analysis\nYour Task: Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.\n\n# Group tracts by whether they have high MOE issues\n# Calculate average characteristics for each group:\n# - population size, demographic percentages\n# Group tracts by whether they have high MOE issues\nmoe_patterns &lt;- demo_moe %&gt;%\n  filter(high_moe_flag == TRUE) %&gt;%   # keep only high-MOE tracts\n  group_by(county_name) %&gt;%\n  summarise(\n    `Population Average` = round(mean(total_popE, na.rm = TRUE), 0),\n    `% White Avg` = round(mean(pct_white, na.rm = TRUE), 2),\n    `% Black Avg` = round(mean(pct_black, na.rm = TRUE), 2),\n    `% LatinX Avg` = round(mean(pct_hispanic, na.rm = TRUE), 2),\n    `Tracts Quantity` = n(),\n    .groups = \"drop\"\n  )\n\nkable(\n  moe_patterns,\n  caption = \"**High-MOE Tracts by County (ACS 2022)**\",\n  align = c(\"l\", \"c\", \"c\", \"c\", \"c\", \"r\"),\n  col.names = c(\"County\", \"Population Average\", \"% White Avg\", \"% Black Avg\", \"% LatinX Avg\", \"Tracts Quantity\"),\n  digits = 2\n) %&gt;%\n  kable_styling(full_width = FALSE, position = \"center\",\n                bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n\n\n**High-MOE Tracts by County (ACS 2022)**\n\n\nCounty\nPopulation Average\n% White Avg\n% Black Avg\n% LatinX Avg\nTracts Quantity\n\n\n\n\nCulberson\n2181\n11.42\n0.18\n81.34\n1\n\n\nDimmit\n2891\n9.60\n0.65\n87.57\n3\n\n\n\n\n# Use group_by() and summarize() to create this comparison\n# Create a professional table showing the patterns\n\nPattern Analysis: High MOE tracts are found in small, rural counties with low populations and high Hispanic/Latino shares.These factors reduce ACS reliability, meaning minority and rural communities face greater risk of being misrepresented in algorithmic decisions."
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment_1.html#analysis-integration-and-professional-summary",
    "href": "Assignments /Assignment_1/Assignment_1.html#analysis-integration-and-professional-summary",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "5.1 Analysis Integration and Professional Summary",
    "text": "5.1 Analysis Integration and Professional Summary\nYour Task: Write an executive summary that integrates findings from all four analyses.\nExecutive Summary Requirements: 1. Overall Pattern Identification: What are the systematic patterns across all your analyses? 2. Equity Assessment: Which communities face the greatest risk of algorithmic bias based on your findings? 3. Root Cause Analysis: What underlying factors drive both data quality issues and bias risk? 4. Strategic Recommendations: What should the Department implement to address these systematic issues?\nExecutive Summary:\nLooking at ACS 2022 data for Texas, we see that data quality isn’t the same everywhere. Larger, urban counties usually have solid numbers, while smaller rural counties often have very high margins of error. In some places, the income data is so uncertain that it’s hard to use with confidence.\nThe biggest risk shows up in rural, Hispanic-majority counties like Dimmit and Culberson. These areas often have the highest uncertainty, which means if an algorithm used this data directly, the results could shortchange the very communities that need the most support.\nThe main reason for this problem is how the ACS survey works. Small populations naturally create bigger sampling errors, and rural or minority communities may also face challenges like language barriers or low response rates. That makes their numbers less reliable.\nTo make decisions fairer, a tiered approach makes sense. Counties with strong data can go into the algorithm as-is. Counties with moderate-quality data should be monitored, and counties with weak data should get extra checks or even manual review. Over time, improving census participation in rural and minority communities would help fix the root of the problem."
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment_1.html#specific-recommendations",
    "href": "Assignments /Assignment_1/Assignment_1.html#specific-recommendations",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "6.3 Specific Recommendations",
    "text": "6.3 Specific Recommendations\nYour Task: Create a decision framework for algorithm implementation.\n\nlibrary(scales)\nlibrary(kableExtra)\n# Create a summary table using your county reliability data\n# Include: county name, median income, MOE percentage, reliability category\n\n# Add a new column with algorithm recommendations using case_when():\n# - High Confidence: \"Safe for algorithmic decisions\"\n# - Moderate Confidence: \"Use with caution - monitor outcomes\"  \n# - Low Confidence: \"Requires manual review or additional data\"\n\nTX_recommendations &lt;- TX_county_reliability %&gt;%\n  select(county_name, med_household_incomeE, med_income_moe_pct, med_income_confi) %&gt;%\n  mutate(\n    `Median Income ($)` = dollar(med_household_incomeE),\n    `MOE (%)` = percent(med_income_moe_pct / 100, accuracy = 0.1),\n    Recommendation = case_when(\n      med_income_confi == \"High Confidence (&lt;5%)\" ~ \"✅ Safe for algorithmic decisions\",\n      med_income_confi == \"Moderate Confidence (5% - 10%)\" ~ \"⚠️ Use with caution – monitor outcomes\",\n      med_income_confi == \"Low Confidence (&gt;10%)\" ~ \"❌ Requires manual review or extra data\",\n      TRUE ~ \"Check data\"\n    )\n  ) %&gt;%\n  select(county_name, `Median Income ($)`, `MOE (%)`, med_income_confi, Recommendation)\n\n\n# Format as a professional table with kable()\nkable(\n  TX_recommendations,\n  caption = \"**County-Level Reliability and Algorithm Recommendations (ACS 2022)**\",\n  col.names = c(\"County\", \"Median Income ($)\", \"MOE (%)\", \"Reliability\", \"Recommendation\"),\n  escape = FALSE,\n  align = c(\"l\", \"r\", \"r\", \"l\", \"l\")\n) %&gt;%\n  kable_styling(full_width = FALSE, position = \"center\",\n                bootstrap_options = c(\"striped\", \"hover\", \"condensed\")) %&gt;%\n  column_spec(1, bold = TRUE)\n\n\n**County-Level Reliability and Algorithm Recommendations (ACS 2022)**\n\n\nCounty\nMedian Income ($)\nMOE (%)\nReliability\nRecommendation\n\n\n\n\nAnderson County\n$57,445\n7.9%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nAndrews County\n$86,458\n18.6%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nAngelina County\n$57,055\n4.4%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nAransas County\n$58,168\n11.1%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nArcher County\n$69,954\n12.1%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nArmstrong County\n$70,417\n20.7%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nAtascosa County\n$67,442\n6.4%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nAustin County\n$73,556\n6.5%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nBailey County\n$69,830\n18.8%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nBandera County\n$70,965\n8.0%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nBastrop County\n$80,151\n6.1%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nBaylor County\n$52,716\n25.1%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nBee County\n$50,283\n10.0%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nBell County\n$62,858\n2.8%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nBexar County\n$67,275\n1.2%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nBlanco County\n$79,717\n9.4%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nBorden County\n$80,625\n24.9%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nBosque County\n$63,868\n6.0%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nBowie County\n$56,628\n4.1%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nBrazoria County\n$91,972\n3.3%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nBrazos County\n$57,562\n3.5%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nBrewster County\n$47,747\n11.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nBriscoe County\n$35,446\n27.6%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nBrooks County\n$30,566\n33.8%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nBrown County\n$53,792\n4.7%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nBurleson County\n$71,745\n6.5%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nBurnet County\n$71,482\n8.1%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nCaldwell County\n$66,779\n7.0%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nCalhoun County\n$62,267\n9.9%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nCallahan County\n$63,906\n3.6%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nCameron County\n$47,435\n3.4%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nCamp County\n$53,968\n7.6%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nCarson County\n$83,199\n4.5%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nCass County\n$54,303\n6.8%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nCastro County\n$59,886\n17.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nChambers County\n$106,103\n8.3%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nCherokee County\n$56,971\n8.5%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nChildress County\n$56,063\n29.3%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nClay County\n$75,227\n7.1%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nCochran County\n$41,597\n17.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nCoke County\n$40,230\n13.8%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nColeman County\n$51,034\n7.9%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nCollin County\n$113,255\n1.2%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nCollingsworth County\n$52,045\n22.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nColorado County\n$63,352\n8.2%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nComal County\n$93,744\n2.8%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nComanche County\n$57,383\n13.3%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nConcho County\n$55,750\n27.9%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nCooke County\n$66,374\n8.4%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nCoryell County\n$63,281\n3.6%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nCottle County\n$47,625\n37.8%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nCrane County\n$71,364\n32.9%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nCrockett County\n$64,103\n34.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nCrosby County\n$50,268\n10.4%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nCulberson County\n$35,924\n51.4%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nDallam County\n$71,969\n9.7%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nDallas County\n$70,732\n0.9%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nDawson County\n$45,268\n27.6%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nDeaf Smith County\n$51,942\n6.0%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nDelta County\n$68,491\n27.8%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nDenton County\n$104,180\n1.3%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nDeWitt County\n$61,100\n7.9%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nDickens County\n$46,638\n13.6%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nDimmit County\n$27,374\n45.2%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nDonley County\n$51,711\n12.4%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nDuval County\n$50,697\n20.3%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nEastland County\n$52,902\n12.2%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nEctor County\n$70,566\n4.2%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nEdwards County\n$40,809\n27.1%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nEllis County\n$93,248\n2.7%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nEl Paso County\n$55,417\n1.9%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nErath County\n$59,654\n6.7%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nFalls County\n$45,172\n15.3%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nFannin County\n$65,835\n6.1%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nFayette County\n$72,881\n5.0%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nFisher County\n$60,461\n8.2%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nFloyd County\n$49,321\n9.0%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nFoard County\n$41,944\n20.9%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nFort Bend County\n$109,987\n2.6%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nFranklin County\n$67,915\n4.4%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nFreestone County\n$55,902\n10.5%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nFrio County\n$56,042\n30.3%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nGaines County\n$73,299\n13.8%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nGalveston County\n$83,913\n2.8%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nGarza County\n$56,215\n35.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nGillespie County\n$70,162\n8.2%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nGlasscock County\n$112,188\n27.9%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nGoliad County\n$58,125\n25.8%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nGonzales County\n$64,255\n8.4%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nGray County\n$54,563\n7.2%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nGrayson County\n$66,608\n3.6%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nGregg County\n$63,811\n3.9%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nGrimes County\n$63,484\n9.1%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nGuadalupe County\n$88,111\n3.9%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nHale County\n$50,721\n9.0%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nHall County\n$43,873\n11.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nHamilton County\n$54,890\n17.3%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nHansford County\n$62,350\n19.7%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nHardeman County\n$60,455\n15.3%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nHardin County\n$70,164\n5.1%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nHarris County\n$70,789\n0.7%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nHarrison County\n$63,427\n4.8%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nHartley County\n$78,065\n27.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nHaskell County\n$52,786\n16.3%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nHays County\n$79,990\n3.7%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nHemphill County\n$67,798\n27.7%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nHenderson County\n$59,778\n4.3%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nHidalgo County\n$49,371\n2.3%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nHill County\n$60,669\n6.0%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nHockley County\n$53,283\n7.5%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nHood County\n$80,013\n4.7%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nHopkins County\n$63,766\n5.7%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nHouston County\n$51,043\n10.5%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nHoward County\n$67,243\n6.5%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nHudspeth County\n$35,163\n23.2%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nHunt County\n$66,885\n4.2%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nHutchinson County\n$62,211\n7.5%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nIrion County\n$54,708\n17.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nJack County\n$58,861\n13.2%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nJackson County\n$67,176\n17.9%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nJasper County\n$48,818\n9.8%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nJeff Davis County\n$38,125\n66.1%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nJefferson County\n$57,294\n2.9%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nJim Hogg County\n$42,292\n13.6%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nJim Wells County\n$46,626\n12.7%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nJohnson County\n$77,058\n3.1%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nJones County\n$59,361\n10.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nKarnes County\n$57,798\n14.5%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nKaufman County\n$84,075\n4.1%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nKendall County\n$104,196\n8.3%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nKenedy County\n$45,455\n25.1%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nKent County\n$68,553\n15.6%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nKerr County\n$66,713\n6.2%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nKimble County\n$62,386\n22.6%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nKing County\n$59,375\n49.5%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nKinney County\n$52,386\n45.3%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nKleberg County\n$52,487\n9.5%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nKnox County\n$48,750\n9.8%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nLamar County\n$58,246\n4.9%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nLamb County\n$54,519\n8.6%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nLampasas County\n$73,269\n7.4%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nLa Salle County\n$62,798\n26.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nLavaca County\n$58,530\n7.7%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nLee County\n$66,448\n10.4%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nLeon County\n$57,363\n12.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nLiberty County\n$59,605\n6.7%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nLimestone County\n$53,102\n7.1%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nLipscomb County\n$71,625\n12.9%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nLive Oak County\n$55,949\n18.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nLlano County\n$64,241\n8.8%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nLoving County\nNA\nNA\nNA\nCheck data\n\n\nLubbock County\n$61,911\n3.5%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nLynn County\n$52,996\n7.1%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nMcCulloch County\n$53,214\n16.8%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nMcLennan County\n$59,781\n3.2%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nMcMullen County\n$60,313\n41.2%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nMadison County\n$65,768\n9.6%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nMarion County\n$48,040\n5.0%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nMartin County\n$70,217\n27.1%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nMason County\n$77,583\n15.8%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nMatagorda County\n$56,412\n6.3%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nMaverick County\n$48,497\n10.1%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nMedina County\n$73,060\n4.0%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nMenard County\n$40,945\n17.9%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nMidland County\n$90,123\n5.8%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nMilam County\n$56,985\n5.9%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nMills County\n$59,315\n9.3%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nMitchell County\n$49,869\n12.5%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nMontague County\n$63,336\n8.6%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nMontgomery County\n$95,946\n3.4%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nMoore County\n$59,041\n6.5%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nMorris County\n$51,532\n6.7%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nMotley County\n$66,528\n8.4%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nNacogdoches County\n$51,153\n4.2%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nNavarro County\n$56,261\n7.7%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nNewton County\n$38,871\n16.9%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nNolan County\n$47,437\n7.7%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nNueces County\n$64,027\n2.3%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nOchiltree County\n$62,240\n17.8%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nOldham County\n$71,103\n11.2%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nOrange County\n$71,910\n7.9%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nPalo Pinto County\n$65,242\n4.4%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nPanola County\n$58,205\n18.3%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nParker County\n$95,721\n3.9%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nParmer County\n$65,575\n13.7%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nPecos County\n$59,325\n17.1%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nPolk County\n$57,315\n5.2%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nPotter County\n$47,974\n4.0%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nPresidio County\n$29,012\n24.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nRains County\n$60,291\n10.8%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nRandall County\n$78,038\n3.5%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nReagan County\n$70,319\n12.8%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nReal County\n$46,842\n33.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nRed River County\n$44,583\n9.7%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nReeves County\n$57,487\n22.1%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nRefugio County\n$54,304\n4.9%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nRoberts County\n$62,667\n14.2%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nRobertson County\n$59,410\n17.7%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nRockwall County\n$121,303\n3.8%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nRunnels County\n$55,424\n6.0%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nRusk County\n$61,661\n9.8%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nSabine County\n$47,061\n16.9%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nSan Augustine County\n$45,888\n9.7%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nSan Jacinto County\n$54,839\n13.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nSan Patricio County\n$63,842\n6.9%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nSan Saba County\n$54,087\n16.4%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nSchleicher County\n$53,774\n15.2%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nScurry County\n$58,932\n21.4%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nShackelford County\n$60,924\n14.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nShelby County\n$49,231\n10.0%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nSherman County\n$66,169\n27.9%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nSmith County\n$69,053\n3.2%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nSomervell County\n$87,899\n33.7%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nStarr County\n$35,979\n8.4%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nStephens County\n$44,712\n18.8%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nSterling County\n$63,558\n22.3%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nStonewall County\n$66,591\n32.5%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nSutton County\n$56,778\n22.7%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nSwisher County\n$40,290\n13.7%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nTarrant County\n$78,872\n1.0%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nTaylor County\n$61,806\n3.9%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nTerrell County\n$52,813\n21.0%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nTerry County\n$42,694\n10.9%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nThrockmorton County\n$55,221\n21.1%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nTitus County\n$57,634\n8.1%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nTom Green County\n$67,215\n4.7%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nTravis County\n$92,731\n1.2%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nTrinity County\n$51,165\n11.4%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nTyler County\n$50,898\n10.3%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nUpshur County\n$60,456\n7.7%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nUpton County\n$55,284\n21.7%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nUvalde County\n$55,000\n15.3%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nVal Verde County\n$57,250\n8.0%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nVan Zandt County\n$62,334\n8.1%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nVictoria County\n$66,308\n3.6%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nWalker County\n$47,193\n6.3%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nWaller County\n$71,643\n6.0%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nWard County\n$70,771\n12.6%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nWashington County\n$70,043\n9.4%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nWebb County\n$59,984\n3.1%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nWharton County\n$59,712\n6.8%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nWheeler County\n$58,158\n14.2%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nWichita County\n$58,862\n3.2%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nWilbarger County\n$50,769\n18.4%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nWillacy County\n$42,839\n13.1%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nWilliamson County\n$102,851\n1.4%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nWilson County\n$89,708\n4.9%\nHigh Confidence (&lt;5%)\n✅ Safe for algorithmic decisions |\n\n\nWinkler County\n$89,155\n16.1%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nWise County\n$85,385\n6.1%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nWood County\n$61,748\n6.0%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nYoakum County\n$80,317\n8.8%\nModerate Confidence (5% - 10%)\n⚠️ Use with caution – monitor outcomes\n\n\nYoung County\n$65,565\n16.9%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nZapata County\n$35,061\n10.7%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\nZavala County\n$49,243\n28.8%\nLow Confidence (&gt;10%)\n❌ Requires manual review or extra data |\n\n\n\n\n\nKey Recommendations:\nYour Task: Use your analysis results to provide specific guidance to the department.\n\nCounties suitable for immediate algorithmic implementation: High-confidence counties such as Bexar, Dallas, Travis, Williamson, and Collin have strong data quality (MOE &lt;5%). These counties are large, urban, and well-sampled, making them reliable for algorithm-driven funding and planning decisions.\nCounties requiring additional oversight: Moderate-confidence counties like Anderson, Bastrop, Caldwell, and Wise fall in the 5–10% MOE range. Algorithms may be used here, but outcomes should be monitored regularly with human oversight to check for misallocations.\nCounties needing alternative approaches: Low-confidence counties such as Dimmit, Culberson, Jeff Davis, King, and Kinney have very high MOEs (&gt;10%, sometimes above 40–60%). These areas need manual review, supplemental surveys, or local administrative data to ensure fair resource distribution."
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment_1.html#questions-for-further-investigation",
    "href": "Assignments /Assignment_1/Assignment_1.html#questions-for-further-investigation",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "Questions for Further Investigation",
    "text": "Questions for Further Investigation\n\nAre high-MOE counties geographically clustered (e.g., along the border or in rural west Texas), and does this spatial pattern affect equity?\nHow do data quality issues change over time — are counties improving or declining in reliability across ACS cycles?\nDo certain demographic groups (Hispanic, Black, rural populations) consistently face higher MOEs, and what targeted outreach could improve data collection?"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment_1.html#submission-checklist",
    "href": "Assignments /Assignment_1/Assignment_1.html#submission-checklist",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "Submission Checklist",
    "text": "Submission Checklist\nBefore submitting your portfolio link on Canvas:\n\n[☑ ] All code chunks run without errors\n[☑ ] All “[Fill this in]” prompts have been completed\n[☑ ] Tables are properly formatted and readable\n[☑ ] Executive summary addresses all four required components\n[☑ ] Portfolio navigation includes this assignment\n[☑ ] Census API key is properly set\n[☑ ] Document renders correctly to HTML\n\nRemember: Submit your portfolio URL on Canvas, not the file itself. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/your_file_name.html"
  },
  {
    "objectID": "labs/lab0/script/lab0_template.html",
    "href": "labs/lab0/script/lab0_template.html",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "",
    "text": "Welcome to your first lab! In this (not graded) assignment, you’ll practice the fundamental dplyr operations I overviewed in class using car sales data. This lab will help you get comfortable with:\n\nBasic data exploration\nColumn selection and manipulation\n\nCreating new variables\nFiltering data\nGrouping and summarizing\n\nInstructions: Copy this template into your portfolio repository under a lab_0/ folder, then complete each section with your code and answers. You will write the code under the comment section in each chunk. Be sure to also copy the data folder into your lab_0 folder."
  },
  {
    "objectID": "labs/lab0/script/lab0_template.html#data-structure-exploration",
    "href": "labs/lab0/script/lab0_template.html#data-structure-exploration",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "1.1 Data Structure Exploration",
    "text": "1.1 Data Structure Exploration\nExplore the structure of your data and answer these questions:\n\n# Use glimpse() to see the data structure\nglimpse(car_data)\n\nRows: 50,000\nColumns: 7\n$ Manufacturer          &lt;chr&gt; \"Ford\", \"Porsche\", \"Ford\", \"Toyota\", \"VW\", \"Ford…\n$ Model                 &lt;chr&gt; \"Fiesta\", \"718 Cayman\", \"Mondeo\", \"RAV4\", \"Polo\"…\n$ `Engine size`         &lt;dbl&gt; 1.0, 4.0, 1.6, 1.8, 1.0, 1.4, 1.8, 1.4, 1.2, 2.0…\n$ `Fuel type`           &lt;chr&gt; \"Petrol\", \"Petrol\", \"Diesel\", \"Hybrid\", \"Petrol\"…\n$ `Year of manufacture` &lt;dbl&gt; 2002, 2016, 2014, 1988, 2006, 2018, 2010, 2015, …\n$ Mileage               &lt;dbl&gt; 127300, 57850, 39190, 210814, 127869, 33603, 866…\n$ Price                 &lt;dbl&gt; 3074, 49704, 24072, 1705, 4101, 29204, 14350, 30…\n\n# Check the column names\nnames(car_data)\n\n[1] \"Manufacturer\"        \"Model\"               \"Engine size\"        \n[4] \"Fuel type\"           \"Year of manufacture\" \"Mileage\"            \n[7] \"Price\"              \n\n# Look at the first few rows\nhead(car_data)\n\n# A tibble: 6 × 7\n  Manufacturer Model     `Engine size` `Fuel type` `Year of manufacture` Mileage\n  &lt;chr&gt;        &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;                       &lt;dbl&gt;   &lt;dbl&gt;\n1 Ford         Fiesta              1   Petrol                       2002  127300\n2 Porsche      718 Caym…           4   Petrol                       2016   57850\n3 Ford         Mondeo              1.6 Diesel                       2014   39190\n4 Toyota       RAV4                1.8 Hybrid                       1988  210814\n5 VW           Polo                1   Petrol                       2006  127869\n6 Ford         Focus               1.4 Petrol                       2018   33603\n# ℹ 1 more variable: Price &lt;dbl&gt;\n\n\nQuestions to answer: - How many rows and columns does the dataset have? - What types of variables do you see (numeric, character, etc.)? - Are there any column names that might cause problems? Why?\nYour answers: - Rows: 50,000 - Columns:7 - Variable types: character - Problematic names:"
  },
  {
    "objectID": "labs/lab0/script/lab0_template.html#tibble-vs-data-frame",
    "href": "labs/lab0/script/lab0_template.html#tibble-vs-data-frame",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "1.2 Tibble vs Data Frame",
    "text": "1.2 Tibble vs Data Frame\nCompare how tibbles and data frames display:\n\n# Look at the tibble version (what we have)\ncar_data\n\n# A tibble: 50,000 × 7\n   Manufacturer Model    `Engine size` `Fuel type` `Year of manufacture` Mileage\n   &lt;chr&gt;        &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;                       &lt;dbl&gt;   &lt;dbl&gt;\n 1 Ford         Fiesta             1   Petrol                       2002  127300\n 2 Porsche      718 Cay…           4   Petrol                       2016   57850\n 3 Ford         Mondeo             1.6 Diesel                       2014   39190\n 4 Toyota       RAV4               1.8 Hybrid                       1988  210814\n 5 VW           Polo               1   Petrol                       2006  127869\n 6 Ford         Focus              1.4 Petrol                       2018   33603\n 7 Ford         Mondeo             1.8 Diesel                       2010   86686\n 8 Toyota       Prius              1.4 Hybrid                       2015   30663\n 9 VW           Polo               1.2 Petrol                       2012   73470\n10 Ford         Focus              2   Diesel                       1992  262514\n# ℹ 49,990 more rows\n# ℹ 1 more variable: Price &lt;dbl&gt;\n\n# Convert to regular data frame and display\ncar_df &lt;- as.data.frame(car_data)\n#car_df\n\nQuestion: What differences do you notice in how they print?\nYour answer: [YOUR ANSWER]"
  },
  {
    "objectID": "labs/lab0/script/lab0_template.html#selecting-columns",
    "href": "labs/lab0/script/lab0_template.html#selecting-columns",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "2.1 Selecting Columns",
    "text": "2.1 Selecting Columns\nPractice selecting different combinations of columns:\n\n# Select just Model and Mileage columns\n\n\n# Select Manufacturer, Price, and Fuel type\n\n\n# Challenge: Select all columns EXCEPT Engine Size"
  },
  {
    "objectID": "labs/lab0/script/lab0_template.html#renaming-columns",
    "href": "labs/lab0/script/lab0_template.html#renaming-columns",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "2.2 Renaming Columns",
    "text": "2.2 Renaming Columns\nLet’s fix a problematic column name:\n\n# Rename 'Year of manufacture' to year\n\n\n# Check that it worked\nnames(car_data)\n\n[1] \"Manufacturer\"        \"Model\"               \"Engine size\"        \n[4] \"Fuel type\"           \"Year of manufacture\" \"Mileage\"            \n[7] \"Price\"              \n\n\nQuestion: Why did we need backticks around Year of manufacture but not around year?\nYour answer: [YOUR ANSWER]"
  },
  {
    "objectID": "labs/lab0/script/lab0_template.html#calculate-car-age",
    "href": "labs/lab0/script/lab0_template.html#calculate-car-age",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "3.1 Calculate Car Age",
    "text": "3.1 Calculate Car Age\n\n# Create an 'age' column (2025 minus year of manufacture)\n\n\n# Create a mileage_per_year column  \n\n\n# Look at your new columns\n#select(car_data, Model, year, age, Mileage, mileage_per_year)"
  },
  {
    "objectID": "labs/lab0/script/lab0_template.html#categorize-cars",
    "href": "labs/lab0/script/lab0_template.html#categorize-cars",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "3.2 Categorize Cars",
    "text": "3.2 Categorize Cars\n\n# Create a price_category column where if price is &lt; 15000, its is coded as budget, between 15000 and 30000 is midrange and greater than 30000 is mid-range (use case_when)\n\n\n# Check your categories select the new column and show it"
  },
  {
    "objectID": "labs/lab0/script/lab0_template.html#basic-filtering",
    "href": "labs/lab0/script/lab0_template.html#basic-filtering",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "4.1 Basic Filtering",
    "text": "4.1 Basic Filtering\n\n# Find all Toyota cars\n\n\n# Find cars with mileage less than 30,000\n\n\n# Find luxury cars (from price category) with low mileage"
  },
  {
    "objectID": "labs/lab0/script/lab0_template.html#multiple-conditions",
    "href": "labs/lab0/script/lab0_template.html#multiple-conditions",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "4.2 Multiple Conditions",
    "text": "4.2 Multiple Conditions\n\n# Find cars that are EITHER Honda OR Nissan\n\n\n# Find cars with price between $20,000 and $35,000\n\n\n# Find diesel cars less than 10 years old\n\nQuestion: How many diesel cars are less than 10 years old?\nYour answer: [YOUR ANSWER]"
  },
  {
    "objectID": "labs/lab0/script/lab0_template.html#basic-summaries",
    "href": "labs/lab0/script/lab0_template.html#basic-summaries",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "5.1 Basic Summaries",
    "text": "5.1 Basic Summaries\n\n# Calculate average price by manufacturer\navg_price_by_brand &lt;- car_data %&gt;%\n  group_by(Manufacturer) %&gt;%\n  summarize(avg_price = mean(Price, na.rm = TRUE))\n\navg_price_by_brand\n\n# A tibble: 5 × 2\n  Manufacturer avg_price\n  &lt;chr&gt;            &lt;dbl&gt;\n1 BMW             24429.\n2 Ford            10672.\n3 Porsche         29104.\n4 Toyota          14340.\n5 VW              10363.\n\n# Calculate average mileage by fuel type\n\n\n# Count cars by manufacturer"
  },
  {
    "objectID": "labs/lab0/script/lab0_template.html#categorical-summaries",
    "href": "labs/lab0/script/lab0_template.html#categorical-summaries",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "5.2 Categorical Summaries",
    "text": "5.2 Categorical Summaries\n\n# Frequency table for price categories"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#what-well-cover",
    "href": "labs/lab1/week-03/lecture/week3.html#what-well-cover",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "What We’ll Cover",
    "text": "What We’ll Cover\nPart 1: Why Visualization Matters\n\nAnscombe’s Quartet and the limits of summary statistics\nVisualization in policy context\nConnection to algorithmic bias and data ethics\n\nPart 2: Grammar of Graphics\n\nggplot2 fundamentals\nAesthetic mappings and geoms\nLive demonstration\n\nPart 3: Exploratory Data Analysis\n\nEDA workflow and principles\nUnderstanding distributions and relationships\nCritical focus: Data quality and uncertainty\n\nPart 4: Data Joins & Integration\n\nCombining datasets with dplyr joins\n\nPart 5: Hands-On Lab\n\nGuided practice with census data\nCreate publication-ready visualizations\nPractice ethical data communication"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#opening-question",
    "href": "labs/lab1/week-03/lecture/week3.html#opening-question",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Opening Question",
    "text": "Opening Question\nThink about Assignment 1:\nYou created tables showing income reliability patterns across counties. But what if you needed to present these findings to:\n\nThe state legislature (2-minute briefing)\nCommunity advocacy groups\nLocal news reporters\n\nDiscussion: How might visual presentation change the impact of your analysis?"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#anscombes-quartet-the-famous-example",
    "href": "labs/lab1/week-03/lecture/week3.html#anscombes-quartet-the-famous-example",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Anscombe’s Quartet: The Famous Example",
    "text": "Anscombe’s Quartet: The Famous Example\nFour datasets with identical summary statistics:\n\nSame means (x̄ = 9, ȳ = 7.5)\nSame variances\nSame correlation (r = 0.816)\nSame regression line\n\nBut completely different patterns when visualized"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#the-policy-implications",
    "href": "labs/lab1/week-03/lecture/week3.html#the-policy-implications",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "The Policy Implications",
    "text": "The Policy Implications\nWhy this matters for your work:\n\nSummary statistics can hide critical patterns\nOutliers may represent important communities\nRelationships aren’t always linear\nVisual inspection reveals data quality issues\n\nExample: A county with “average” income might have extreme inequality that algorithms would miss without visualization."
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#connecting-week-2-ethical-data-communication",
    "href": "labs/lab1/week-03/lecture/week3.html#connecting-week-2-ethical-data-communication",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Connecting Week 2: Ethical Data Communication",
    "text": "Connecting Week 2: Ethical Data Communication\nFrom last week’s algorithmic bias discussion:\nResearch finding: Only 27% of planners warn users about unreliable ACS data - Most planners don’t report margins of error - Many lack training on statistical uncertainty - This violates AICP Code of Ethics\nYour responsibility:\n\nCreate honest, transparent visualizations\nAlways assess and communicate data quality\nConsider who might be harmed by uncertain data"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#bad-visualizations-have-real-consequences",
    "href": "labs/lab1/week-03/lecture/week3.html#bad-visualizations-have-real-consequences",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Bad Visualizations Have Real Consequences",
    "text": "Bad Visualizations Have Real Consequences\nCommon problems in government data presentation:\n\nMisleading scales or axes\nCherry-picked time periods\n\nHidden or ignored uncertainty\nMissing context about data reliability\n\nReal impact: The Jurjevich et al. study found that 72% of Portland census tracts had unreliable child poverty estimates, yet planners rarely communicated this uncertainty.\nResult: Poor policy decisions based on misunderstood data"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#the-ggplot2-philosophy",
    "href": "labs/lab1/week-03/lecture/week3.html#the-ggplot2-philosophy",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "The ggplot2 Philosophy",
    "text": "The ggplot2 Philosophy\nGrammar of Graphics principles:\nData → Aesthetics → Geometries → Visual\n\nData: Your dataset (census data, survey responses, etc.)\nAesthetics: What variables map to visual properties (x, y, color, size)\nGeometries: How to display the data (points, bars, lines)\nAdditional layers: Scales, themes, facets, annotations"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#basic-ggplot2-structure",
    "href": "labs/lab1/week-03/lecture/week3.html#basic-ggplot2-structure",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Basic ggplot2 Structure",
    "text": "Basic ggplot2 Structure\nEvery ggplot has this pattern:\nggplot(data = your_data) +   aes(x = variable1, y = variable2) +   geom_something() +   additional_layers()\nYou build plots by adding layers with +"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#live-demo-basic-scatter-plot",
    "href": "labs/lab1/week-03/lecture/week3.html#live-demo-basic-scatter-plot",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Live Demo: Basic Scatter Plot",
    "text": "Live Demo: Basic Scatter Plot"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#aesthetic-mappings-the-key-to-ggplot2",
    "href": "labs/lab1/week-03/lecture/week3.html#aesthetic-mappings-the-key-to-ggplot2",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Aesthetic Mappings: The Key to ggplot2",
    "text": "Aesthetic Mappings: The Key to ggplot2\nAesthetics map data to visual properties:\n\nx, y - position\ncolor - point/line color\nfill - area fill color\n\nsize - point/line size\nshape - point shape\nalpha - transparency\n\nImportant: Aesthetics go inside aes(), constants go outside"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#improving-plots-with-labels-and-themes",
    "href": "labs/lab1/week-03/lecture/week3.html#improving-plots-with-labels-and-themes",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Improving Plots with Labels and Themes",
    "text": "Improving Plots with Labels and Themes"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#the-eda-mindset",
    "href": "labs/lab1/week-03/lecture/week3.html#the-eda-mindset",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "The EDA Mindset",
    "text": "The EDA Mindset\nExploratory Data Analysis is detective work:\n\nWhat does the data look like? (distributions, missing values)\nWhat patterns exist? (relationships, clusters, trends)\n\nWhat’s unusual? (outliers, anomalies, data quality issues)\nWhat questions does this raise? (hypotheses for further investigation)\nHow reliable is this data?\n\nGoal: Understand your data before making decisions or building models"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#eda-workflow-with-data-quality-focus",
    "href": "labs/lab1/week-03/lecture/week3.html#eda-workflow-with-data-quality-focus",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "EDA Workflow with Data Quality Focus",
    "text": "EDA Workflow with Data Quality Focus\nEnhanced process for policy analysis:\n\nLoad and inspect - dimensions, variable types, missing data\nAssess reliability - examine margins of error, calculate coefficients of variation\nVisualize distributions - histograms, boxplots for each variable\nExplore relationships - scatter plots, correlations\nIdentify patterns - grouping, clustering, geographical patterns\nQuestion anomalies - investigate outliers and unusual patterns\nDocument limitations - prepare honest communication about data quality"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#understanding-distributions",
    "href": "labs/lab1/week-03/lecture/week3.html#understanding-distributions",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Understanding Distributions",
    "text": "Understanding Distributions\nWhy distribution shape matters:\n\nWhat to look for: Skewness, outliers, multiple peaks, gaps"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#boxplots",
    "href": "labs/lab1/week-03/lecture/week3.html#boxplots",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Boxplots!",
    "text": "Boxplots!"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#critical-data-quality-through-visualization",
    "href": "labs/lab1/week-03/lecture/week3.html#critical-data-quality-through-visualization",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Critical: Data Quality Through Visualization",
    "text": "Critical: Data Quality Through Visualization\nResearch insight: Most planners don’t visualize or communicate uncertainty\n\nPattern: Smaller populations have higher uncertainty Ethical implication: These communities might be systematically undercounted"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#research-based-recommendations-for-planners",
    "href": "labs/lab1/week-03/lecture/week3.html#research-based-recommendations-for-planners",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Research-Based Recommendations for Planners",
    "text": "Research-Based Recommendations for Planners\nJurjevich et al. (2018): 5 Essential Guidelines for Using ACS Data\n\nReport the corresponding MOEs of ACS estimates - Always include margin of error values\nInclude a footnote when not reporting MOEs - Explicitly acknowledge omission\n\nProvide context for (un)reliability - Use coefficient of variation (CV):\n\nCV &lt; 12% = reliable (green coding)\nCV 12-40% = somewhat reliable (yellow)\nCV &gt; 40% = unreliable (red coding)\n\nReduce statistical uncertainty - Collapse data detail, aggregate geographies, use multi-year estimates\nAlways conduct statistical significance tests when comparing ACS estimates over time\n\nKey insight: These practices are not just technical best practices—they are ethical requirements under the AICP Code of Ethics"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#eda-for-policy-analysis",
    "href": "labs/lab1/week-03/lecture/week3.html#eda-for-policy-analysis",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "EDA for Policy Analysis",
    "text": "EDA for Policy Analysis\nKey questions for census data:\n\nGeographic patterns: Are problems concentrated in certain areas?\nPopulation relationships: How does size affect data quality?\nDemographic patterns: Are certain communities systematically different?\nTemporal trends: How do patterns change over time?\nData integrity: Where might survey bias affect results?\nReliability assessment: Which estimates should we trust?"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#why-join-data",
    "href": "labs/lab1/week-03/lecture/week3.html#why-join-data",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Why Join Data?",
    "text": "Why Join Data?\nTo combining datasets of course:\n\nCensus demographics + Economic indicators\nSurvey responses + Geographic boundaries\n\nCurrent data + Historical trends\nAdministrative records + Survey data"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#types-of-joins-tabular",
    "href": "labs/lab1/week-03/lecture/week3.html#types-of-joins-tabular",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Types of Joins (tabular)",
    "text": "Types of Joins (tabular)\nFour main types in dplyr:\n\nleft_join() - Keep all rows from left dataset\nright_join() - Keep all rows from right dataset\n\ninner_join() - Keep only rows that match in both\nfull_join() - Keep all rows from both datasets\n\nMost common: left_join() to add columns to your main dataset"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#live-demo-joining-census-tables",
    "href": "labs/lab1/week-03/lecture/week3.html#live-demo-joining-census-tables",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Live Demo: Joining Census Tables",
    "text": "Live Demo: Joining Census Tables\n\n\n# A tibble: 6 × 6\n  GEOID NAME                    median_income income_moe college_pop college_moe\n  &lt;chr&gt; &lt;chr&gt;                           &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1 42001 Adams County, Pennsylv…         78975       3334       10195         761\n2 42003 Allegheny County, Penn…         72537        869      229538        3311\n3 42005 Armstrong County, Penn…         61011       2202        6171         438\n4 42007 Beaver County, Pennsyl…         67194       1531       22588        1012\n5 42009 Bedford County, Pennsy…         58337       2606        3396         307\n6 42011 Berks County, Pennsylv…         74617       1191       50120        1654"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#checking-join-results-and-data-quality",
    "href": "labs/lab1/week-03/lecture/week3.html#checking-join-results-and-data-quality",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Checking Join Results and Data Quality",
    "text": "Checking Join Results and Data Quality\nAlways verify joins AND assess combined reliability:\n\n\nIncome data rows: 67 \n\n\nEducation data rows: 67 \n\n\nCombined data rows: 67 \n\n\n# A tibble: 1 × 2\n  missing_income missing_education\n           &lt;int&gt;             &lt;int&gt;\n1              0                 0\n\n\n# A tibble: 6 × 3\n  NAME                           income_cv college_cv\n  &lt;chr&gt;                              &lt;dbl&gt;      &lt;dbl&gt;\n1 Adams County, Pennsylvania          4.22       7.46\n2 Allegheny County, Pennsylvania      1.20       1.44\n3 Armstrong County, Pennsylvania      3.61       7.10\n4 Beaver County, Pennsylvania         2.28       4.48\n5 Bedford County, Pennsylvania        4.47       9.04\n6 Berks County, Pennsylvania          1.60       3.30"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#lab-structure-for-today",
    "href": "labs/lab1/week-03/lecture/week3.html#lab-structure-for-today",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Lab Structure for Today",
    "text": "Lab Structure for Today\nYou’ll work through six exercises:\n\nFinding Census Variables - Learn to search for the data you need\nSingle Variable EDA - Explore distributions and identify outliers\nTwo Variable Relationships - Create meaningful scatter plots\nData Quality Visualization - Practice ethical uncertainty communication\nMultiple Variables - Color, faceting, and complex relationships\nData Integration - Join datasets and create publication-ready visualizations"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#skills-youll-practice",
    "href": "labs/lab1/week-03/lecture/week3.html#skills-youll-practice",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Skills You’ll Practice",
    "text": "Skills You’ll Practice\nggplot2 fundamentals:\n\nScatter plots, histograms, boxplots\nAesthetic mappings and customization\nProfessional themes and labels\n\nEDA workflow:\n\nDistribution analysis\nOutlier detection\n\nPattern identification\n\nEthical data practice:\n\nVisualizing and reporting margins of error\nUsing coefficient of variation to assess reliability"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#connection-to-professional-ethics",
    "href": "labs/lab1/week-03/lecture/week3.html#connection-to-professional-ethics",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Connection to Professional Ethics",
    "text": "Connection to Professional Ethics\nBy the end of today, you’ll be able to:\n\nVisually assess data quality issues\nCreate compelling presentations of demographic patterns\nCommunicate statistical uncertainty ethically and clearly\nIntegrate multiple data sources"
  },
  {
    "objectID": "labs/lab1/week-03/lecture/week3.html#questions-before-we-begin",
    "href": "labs/lab1/week-03/lecture/week3.html#questions-before-we-begin",
    "title": "Data Visualization & Exploratory Analysis",
    "section": "Questions Before We Begin?",
    "text": "Questions Before We Begin?\nReady for hands-on practice?\nRemember: Today’s skills build directly on Week 1-2 foundations:\n\nSame dplyr functions, now with visualization\nSame census data concepts, now with multiple tables\n\nLet’s create some beautiful graphs"
  },
  {
    "objectID": "labs/lab1/week-03/script/week3_lab_exercise.html",
    "href": "labs/lab1/week-03/script/week3_lab_exercise.html",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "",
    "text": "# Load required packages\nlibrary(tidyverse)\nlibrary(tidycensus)\nlibrary(scales)\nlibrary(RColorBrewer)\n# Set your Census API key if you haven't already\ncensus_api_key(\"ec702835845a134b4376c60759aa72ce62f6df59\")\n\n# We'll use Pennsylvania data for consistency with previous weeks\nstate_choice &lt;- \"PA\""
  },
  {
    "objectID": "labs/lab1/week-03/script/week3_lab_exercise.html#setup-and-data-loading",
    "href": "labs/lab1/week-03/script/week3_lab_exercise.html#setup-and-data-loading",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "",
    "text": "# Load required packages\nlibrary(tidyverse)\nlibrary(tidycensus)\nlibrary(scales)\nlibrary(RColorBrewer)\n# Set your Census API key if you haven't already\ncensus_api_key(\"ec702835845a134b4376c60759aa72ce62f6df59\")\n\n# We'll use Pennsylvania data for consistency with previous weeks\nstate_choice &lt;- \"PA\""
  },
  {
    "objectID": "labs/lab1/week-03/script/week3_lab_exercise.html#exercise-0-finding-census-variable-codes",
    "href": "labs/lab1/week-03/script/week3_lab_exercise.html#exercise-0-finding-census-variable-codes",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Exercise 0: Finding Census Variable Codes",
    "text": "Exercise 0: Finding Census Variable Codes\nThe Challenge: You know you want data on total population, median income, and median age, but you don’t know the specific Census variable codes. How do you find them?\n\n0.1 Load the Variable Dictionary\n\n# Load all available variables for ACS 5-year 2022\nacs_vars_2022 &lt;- load_variables(2022, \"acs5\", cache = TRUE)\n\n# Look at the structure\nglimpse(acs_vars_2022)\n\nRows: 28,152\nColumns: 4\n$ name      &lt;chr&gt; \"B01001A_001\", \"B01001A_002\", \"B01001A_003\", \"B01001A_004\", …\n$ label     &lt;chr&gt; \"Estimate!!Total:\", \"Estimate!!Total:!!Male:\", \"Estimate!!To…\n$ concept   &lt;chr&gt; \"Sex by Age (White Alone)\", \"Sex by Age (White Alone)\", \"Sex…\n$ geography &lt;chr&gt; \"tract\", \"tract\", \"tract\", \"tract\", \"tract\", \"tract\", \"tract…\n\nhead(acs_vars_2022)\n\n# A tibble: 6 × 4\n  name        label                                   concept          geography\n  &lt;chr&gt;       &lt;chr&gt;                                   &lt;chr&gt;            &lt;chr&gt;    \n1 B01001A_001 Estimate!!Total:                        Sex by Age (Whi… tract    \n2 B01001A_002 Estimate!!Total:!!Male:                 Sex by Age (Whi… tract    \n3 B01001A_003 Estimate!!Total:!!Male:!!Under 5 years  Sex by Age (Whi… tract    \n4 B01001A_004 Estimate!!Total:!!Male:!!5 to 9 years   Sex by Age (Whi… tract    \n5 B01001A_005 Estimate!!Total:!!Male:!!10 to 14 years Sex by Age (Whi… tract    \n6 B01001A_006 Estimate!!Total:!!Male:!!15 to 17 years Sex by Age (Whi… tract    \n\n\nWhat you see:\n\nname: The variable code (e.g., “B01003_001”)\nlabel: Human-readable description\nconcept: The broader table this variable belongs to\n\n\n\n0.2 Search for Population Variables\nYour Task: Find the variable code for total population.\n\n# Search for population-related variables\npopulation_vars &lt;- acs_vars_2022 %&gt;%\n  filter(str_detect(label, \"Total.*population\"))\n\n# Look at the results\nhead(population_vars, 10)\n\n# A tibble: 10 × 4\n   name       label                                            concept geography\n   &lt;chr&gt;      &lt;chr&gt;                                            &lt;chr&gt;   &lt;chr&gt;    \n 1 B16008_002 \"Estimate!!Total:!!Native population:\"           Citize… tract    \n 2 B16008_003 \"Estimate!!Total:!!Native population:!!5 to 17 … Citize… tract    \n 3 B16008_004 \"Estimate!!Total:!!Native population:!!5 to 17 … Citize… tract    \n 4 B16008_005 \"Estimate!!Total:!!Native population:!!5 to 17 … Citize… tract    \n 5 B16008_006 \"Estimate!!Total:!!Native population:!!5 to 17 … Citize… tract    \n 6 B16008_007 \"Estimate!!Total:!!Native population:!!5 to 17 … Citize… tract    \n 7 B16008_008 \"Estimate!!Total:!!Native population:!!5 to 17 … Citize… tract    \n 8 B16008_009 \"Estimate!!Total:!!Native population:!!5 to 17 … Citize… tract    \n 9 B16008_010 \"Estimate!!Total:!!Native population:!!5 to 17 … Citize… tract    \n10 B16008_011 \"Estimate!!Total:!!Native population:!!18 years… Citize… tract    \n\n# Or search in the concept field\npop_concept &lt;- acs_vars_2022 %&gt;%\n  filter(str_detect(concept, \"Total Population\"))\n\nhead(pop_concept)\n\n# A tibble: 6 × 4\n  name        label                             concept                geography\n  &lt;chr&gt;       &lt;chr&gt;                             &lt;chr&gt;                  &lt;chr&gt;    \n1 B01003_001  Estimate!!Total                   Total Population       block gr…\n2 B25008A_001 Estimate!!Total:                  Total Population in O… block gr…\n3 B25008A_002 Estimate!!Total:!!Owner occupied  Total Population in O… block gr…\n4 B25008A_003 Estimate!!Total:!!Renter occupied Total Population in O… block gr…\n5 B25008B_001 Estimate!!Total:                  Total Population in O… block gr…\n6 B25008B_002 Estimate!!Total:!!Owner occupied  Total Population in O… block gr…\n\n\nTip: Look for “Total” followed by “population” - usually B01003_001\n\n\n0.3 Search for Income Variables\nYour Task: Find median household income variables.\n\n# Search for median income\nincome_vars &lt;- acs_vars_2022 %&gt;%\n  filter(str_detect(label, \"[Mm]edian.*income\"))\n\n# Look specifically for household income\nhousehold_income &lt;- income_vars %&gt;%\n  filter(str_detect(label, \"household\"))\n\nprint(\"Household income variables:\")\n\n[1] \"Household income variables:\"\n\nhead(household_income)\n\n# A tibble: 6 × 4\n  name        label                                            concept geography\n  &lt;chr&gt;       &lt;chr&gt;                                            &lt;chr&gt;   &lt;chr&gt;    \n1 B10010_002  Estimate!!Median family income in the past 12 m… Median… tract    \n2 B10010_003  Estimate!!Median family income in the past 12 m… Median… tract    \n3 B19013A_001 Estimate!!Median household income in the past 1… Median… tract    \n4 B19013B_001 Estimate!!Median household income in the past 1… Median… tract    \n5 B19013C_001 Estimate!!Median household income in the past 1… Median… tract    \n6 B19013D_001 Estimate!!Median household income in the past 1… Median… tract    \n\n# Alternative: search by concept\nincome_concept &lt;- acs_vars_2022 %&gt;%\n  filter(str_detect(concept, \"Median Household Income\"))\n\nhead(income_concept)\n\n# A tibble: 6 × 4\n  name        label                                            concept geography\n  &lt;chr&gt;       &lt;chr&gt;                                            &lt;chr&gt;   &lt;chr&gt;    \n1 B19013A_001 Estimate!!Median household income in the past 1… Median… tract    \n2 B19013B_001 Estimate!!Median household income in the past 1… Median… tract    \n3 B19013C_001 Estimate!!Median household income in the past 1… Median… tract    \n4 B19013D_001 Estimate!!Median household income in the past 1… Median… tract    \n5 B19013E_001 Estimate!!Median household income in the past 1… Median… county   \n6 B19013F_001 Estimate!!Median household income in the past 1… Median… tract    \n\n\nPattern Recognition: Median household income is typically B19013_001\n\n\n0.4 Search for Age Variables\nYour Task: Find median age variables."
  },
  {
    "objectID": "labs/lab1/week-03/script/week3_lab_exercise.html#exercise-1-single-variable-eda",
    "href": "labs/lab1/week-03/script/week3_lab_exercise.html#exercise-1-single-variable-eda",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Exercise 1: Single Variable EDA",
    "text": "Exercise 1: Single Variable EDA\n\n1.1 Load and Inspect Data\n\n# Get county-level data for your state\ncounty_data &lt;- get_acs(\n  geography = \"county\",\n  variables = c(\n    total_pop = \"B01003_001\",       # Total population\n    median_income = \"B19013_001\",   # Median household income\n    median_age = \"B01002_001\"       # Median age\n  ),\n  state = state_choice,\n  year = 2022,\n  output = \"wide\"\n)\n\n# Clean county names\ncounty_data &lt;- county_data %&gt;%\n  mutate(county_name = str_remove(NAME, paste0(\", Pennsylvania\")))\n\n# Basic inspection\nglimpse(county_data)\n\nRows: 67\nColumns: 9\n$ GEOID          &lt;chr&gt; \"42001\", \"42003\", \"42005\", \"42007\", \"42009\", \"42011\", \"…\n$ NAME           &lt;chr&gt; \"Adams County, Pennsylvania\", \"Allegheny County, Pennsy…\n$ total_popE     &lt;dbl&gt; 104604, 1245310, 65538, 167629, 47613, 428483, 122640, …\n$ total_popM     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ median_incomeE &lt;dbl&gt; 78975, 72537, 61011, 67194, 58337, 74617, 59386, 60650,…\n$ median_incomeM &lt;dbl&gt; 3334, 869, 2202, 1531, 2606, 1191, 2058, 2167, 1516, 21…\n$ median_ageE    &lt;dbl&gt; 43.8, 40.6, 47.0, 44.9, 47.3, 39.9, 42.9, 43.9, 44.0, 4…\n$ median_ageM    &lt;dbl&gt; 0.2, 0.1, 0.2, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, …\n$ county_name    &lt;chr&gt; \"Adams County\", \"Allegheny County\", \"Armstrong County\",…\n\n\n\n\n1.2 Explore Income Distribution\nYour Task: Create a histogram of median household income and describe what you see.\n\n# Create histogram of median income\nggplot(county_data) +\n  aes(x = median_incomeE) +\n  geom_histogram(bins = 15, fill = \"lightpink\", alpha = 0.5) +\n  labs(\n    title = \"Distribution of Median Household Income\",\n    x = \"Median Household Income ($)\",\n    y = \"Number of Counties\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(labels = dollar)\n\n\n\n\n\n\n\n\n\n\n1.3 Box Plot for Outlier Detection\nYour Task: Create a boxplot to identify specific outlier counties.\n\n# Box plot to see outliers clearly\nggplot(county_data) +\n  aes(y = median_incomeE) +\n  geom_boxplot(fill = \"lightpink\", width = 0.5) +\n  labs(\n    title = \"Median Income Distribution with Outliers\",\n    y = \"Median Household Income ($)\"\n  ) +\n  theme_minimal() +\n  scale_y_continuous(labels = dollar)\n\n\n\n\n\n\n\n# Identify the outlier counties\nincome_outliers &lt;- county_data %&gt;%\n  mutate(\n    Q1 = quantile(median_incomeE, 0.25, na.rm = TRUE),\n    Q3 = quantile(median_incomeE, 0.75, na.rm = TRUE),\n    IQR = Q3 - Q1,\n    outlier = median_incomeE &lt; (Q1 - 1.5 * IQR) | median_incomeE &gt; (Q3 + 1.5 * IQR)\n  ) %&gt;%\n  filter(outlier) %&gt;%\n  select(county_name, median_incomeE)\n\nprint(\"Outlier counties:\")\n\n[1] \"Outlier counties:\"\n\nincome_outliers\n\n# A tibble: 3 × 2\n  county_name       median_incomeE\n  &lt;chr&gt;                      &lt;dbl&gt;\n1 Bucks County              107826\n2 Chester County            118574\n3 Montgomery County         107441\n\n\n\n\n1.4 Challenge Exercise: Population Distribution\nYour Task: Create your own visualization of population distribution and identify outliers.\nRequirements:\n\nCreate a histogram of total population (total_popE)\nUse a different color than the income example (try “darkgreen” or “purple”)\nAdd appropriate labels and title\nCreate a boxplot to identify population outliers\nFind and list the 3 most populous and 3 least populous counties\n\n\n# Create histogram of total population\nggplot(county_data) +\n  aes(x = total_popE) +\n  geom_histogram(bins = 15, fill = \"lightpink\", alpha = 0.7) +\n  labs(\n    title = \"Total Population Distribution\",\n    x = \"Population\",\n    y = \"Number of Counties\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(labels=comma)\n\n\n\n\n\n\n\n\n\n# Box plot to see outliers clearly\nggplot(county_data) +\n  aes(y = total_popE) +\n  geom_boxplot(fill = \"lightpink\", width = 0.5) +\n  labs(\n    title = \"Total population distribution with Outliers\",\n    y = \"Population\"\n  ) +\n  theme_minimal() +\n  scale_y_continuous(labels=comma)\n\n\n\n\n\n\n\n# Identify the outlier counties\npopulation_outliers &lt;- county_data %&gt;%\n  mutate(\n    Q1 = quantile(total_popE, 0.25, na.rm = TRUE),\n    Q3 = quantile(total_popE, 0.75, na.rm = TRUE),\n    IQR = Q3 - Q1,\n    outlier = total_popE &lt; (Q1 - 1.5 * IQR) | total_popE &gt; (Q3 + 1.5 * IQR)\n  ) %&gt;%\n  filter(outlier) %&gt;%\n  select(county_name, total_popE)\n\nprint(\"Outlier counties:\")\n\n[1] \"Outlier counties:\"\n\npopulation_outliers\n\n# A tibble: 7 × 2\n  county_name         total_popE\n  &lt;chr&gt;                    &lt;dbl&gt;\n1 Allegheny County       1245310\n2 Bucks County            645163\n3 Chester County          536474\n4 Delaware County         575312\n5 Lancaster County        553202\n6 Montgomery County       856399\n7 Philadelphia County    1593208"
  },
  {
    "objectID": "labs/lab1/week-03/script/week3_lab_exercise.html#exercise-2-two-variable-relationships",
    "href": "labs/lab1/week-03/script/week3_lab_exercise.html#exercise-2-two-variable-relationships",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Exercise 2: Two Variable Relationships",
    "text": "Exercise 2: Two Variable Relationships\n\n2.1 Population vs Income Scatter Plot\nYour Task: Explore the relationship between population size and median income.\n\n# Basic scatter plot\nggplot(county_data) +\n  aes(x = total_popE, y = median_incomeE) +\n  geom_point() +\n  labs(\n    title = \"Population vs Median Income\",\n    x = \"Total Population\",\n    y = \"Median Household Income ($)\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(labels = comma) +\n  scale_y_continuous(labels = dollar)\n\n\n\n\n\n\n\n\n\n\n2.2 Add Trend Line and Labels\nYour Task: Improve the plot by adding a trend line and labeling interesting points.\n\n# Enhanced scatter plot with trend line\nggplot(county_data) +\n  aes(x = total_popE, y = median_incomeE) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"lightpink\") +\n  labs(\n    title = \"Population vs Median Income in Pennsylvania Counties\",\n    subtitle = \"2018-2022 ACS 5-Year Estimates\",\n    x = \"Total Population\",\n    y = \"Median Household Income ($)\",\n    caption = \"Source: U.S. Census Bureau\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(labels = comma) +\n  scale_y_continuous(labels = dollar)\n\n\n\n\n\n\n\n# Calculate correlation\ncorrelation &lt;- cor(county_data$total_popE, county_data$median_incomeE, use = \"complete.obs\")\nprint(paste(\"Correlation coefficient:\", round(correlation, 3)))\n\n[1] \"Correlation coefficient: 0.457\"\n\n\n\n\n2.3 Deal with Skewed Data\nYour Task: The population data is highly skewed. Try a log transformation.\n\n# Log-transformed scatter plot\nggplot(county_data) +\n  aes(x = log(total_popE), y = median_incomeE) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  labs(\n    title = \"Log(Population) vs Median Income\",\n    x = \"Log(Total Population)\",\n    y = \"Median Household Income ($)\"\n  ) +\n  theme_minimal() +\n  scale_y_continuous(labels = dollar)\n\n\n\n\n\n\n\n\nQuestion: Does the log transformation reveal a clearer relationship? Yes. It’s a positive slope, it suggests that more populous counties tend to have higher median household incomes.\n\n\n2.4 Challenge Exercise: Age vs Income Relationship\nYour Task: Explore the relationship between median age and median income using different visualization techniques.\nRequirements:\n\nCreate a scatter plot with median age on x-axis and median income on y-axis\nUse red points (color = \"red\") with 50% transparency (alpha = 0.5)\nAdd a smooth trend line using method = \"loess\" instead of “lm”\nUse the “dark” theme (theme_dark())\nFormat the y-axis with dollar signs\nAdd a title that mentions both variables\n\n\n# Enhanced scatter plot with trend line\nggplot(county_data) +\n  aes(x = median_ageE, y = median_incomeE) +\n  geom_point(alpha = 0.5, color = \"red\") +\n  geom_smooth(method = \"loess\", se = TRUE, color = \"red\") +\n  labs(\n    title = \"Median Age vs Median Income in Pennsylvania Counties\",\n    subtitle = \"2018-2022 ACS 5-Year Estimates\",\n    x = \"Median Age\",\n    y = \"Median Household Income ($)\",\n    caption = \"Source: U.S. Census Bureau\"\n  ) +\n  theme_dark() +\n  scale_x_continuous(labels = comma) +\n  scale_y_continuous(labels = dollar)\n\n\n\n\n\n\n\n# Calculate correlation\ncorrelation &lt;- cor(county_data$total_popE, county_data$median_incomeE, use = \"complete.obs\")\nprint(paste(\"Correlation coefficient:\", round(correlation, 3)))\n\n[1] \"Correlation coefficient: 0.457\""
  },
  {
    "objectID": "labs/lab1/week-03/script/week3_lab_exercise.html#exercise-3-data-quality-visualization",
    "href": "labs/lab1/week-03/script/week3_lab_exercise.html#exercise-3-data-quality-visualization",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Exercise 3: Data Quality Visualization",
    "text": "Exercise 3: Data Quality Visualization\n\n3.1 Visualize Margins of Error\nYour Task: Create a visualization showing how data reliability varies across counties.\n\n# Calculate MOE percentages\ncounty_reliability &lt;- county_data %&gt;%\n  mutate(\n    income_moe_pct = (median_incomeM / median_incomeE) * 100,\n    pop_category = case_when(\n      total_popE &lt; 50000 ~ \"Small (&lt;50K)\",\n      total_popE &lt; 200000 ~ \"Medium (50K-200K)\",\n      TRUE ~ \"Large (200K+)\"\n    )\n  )\n\n# MOE by population size\nggplot(county_reliability) +\n  aes(x = total_popE, y = income_moe_pct) +\n  geom_point(alpha = 0.7) +\n  geom_hline(yintercept = 10, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Data Reliability Decreases with Population Size\",\n    x = \"Total Population\",\n    y = \"Margin of Error (%)\",\n    caption = \"Red line = 10% reliability threshold\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(labels = scales::comma)\n\n\n\n\n\n\n\n\n\n\n3.2 Compare Reliability by County Size\nYour Task: Use box plots to compare MOE across county size categories.\n\n# Box plots by population category\nggplot(county_reliability) +\n  aes(x = pop_category, y = income_moe_pct, fill = pop_category) +\n  geom_boxplot() +\n  labs(\n    title = \"Data Reliability by County Size Category\",\n    x = \"Population Category\",\n    y = \"Margin of Error (%)\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")  # Remove legend since x-axis is clear\n\n\n\n\n\n\n\n\n\n\n3.3 Challenge Exercise: Age Data Reliability\nYour Task: Analyze the reliability of median age data across counties.\nRequirements:\n\nCalculate MOE percentage for median age (median_ageM / median_ageE * 100)\nCreate a scatter plot showing population vs age MOE percentage\nUse purple points (color = \"purple\") with size = 2\nAdd a horizontal line at 5% MOE using geom_hline() with a blue dashed line\nUse theme_classic()instead of theme_minimal()\nCreate a boxplot comparing age MOE across the three population categories\n\n\n# Calculate MOE percentages\ncounty_reliability &lt;- county_data %&gt;%\n  mutate(\n    age_moe_pct = (median_ageM / median_ageE) * 100,\n    pop_category = case_when(\n      median_ageE &lt; 40 ~ \"Small (&lt;40)\",\n      median_ageE &lt; 50 ~ \"Medium (40-50)\",\n      TRUE ~ \"Large (&gt;50)\"\n    )\n  )\n\n# MOE by population size\nggplot(county_reliability) +\n  aes(x = median_ageE, y = age_moe_pct) +\n  geom_point(alpha = 0.7, color = \"purple\",size = 2) +\n  geom_hline(yintercept = 5, color = \"blue\", linetype = \"dashed\",size = 0.5 ) +\n  labs(\n    title = \"Data Reliability of median age data across\ncounties.\",\n    x = \"Median Age\",\n    y = \"Margin of Error (%)\",\n    caption = \"Red line = 5% reliability threshold\"\n  ) +\n  theme_classic() +\n  scale_x_continuous(labels = comma)\n\n\n\n\n\n\n\n\n\n# Box plots by population category\nggplot(county_reliability) +\n  aes(x = pop_category, y = age_moe_pct, fill = pop_category) +\n  geom_boxplot() +\n  labs(\n    title = \"age MOE across the three population categories\",\n    x = \"Population Category\",\n    y = \"Margin of Error (%)\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")  # Remove legend since x-axis is clear"
  },
  {
    "objectID": "labs/lab1/week-03/script/week3_lab_exercise.html#exercise-4-multiple-variables-with-color-and-faceting",
    "href": "labs/lab1/week-03/script/week3_lab_exercise.html#exercise-4-multiple-variables-with-color-and-faceting",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Exercise 4: Multiple Variables with Color and Faceting",
    "text": "Exercise 4: Multiple Variables with Color and Faceting\n\n4.1 Three-Variable Scatter Plot\nYour Task: Add median age as a color dimension to the population-income relationship.\n\n# Three-variable scatter plot\nggplot(county_data) +\n  aes(x = total_popE, y = median_incomeE, color = median_ageE) +\n  geom_point(size = 2, alpha = 0.7) +\n  scale_color_viridis_c(name = \"Median\\nAge\") +\n  labs(\n    title = \"Population, Income, and Age Patterns\",\n    x = \"Total Population\",\n    y = \"Median Household Income ($)\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(labels = comma) +\n  scale_y_continuous(labels = dollar)\n\n\n\n\n\n\n\n\n\n\n4.2 Create Categories for Faceting\nYour Task: Create age categories and use faceting to compare patterns.\n\n# Create age categories and faceted plot\ncounty_faceted &lt;- county_data %&gt;%\n  mutate(\n    age_category = case_when(\n      median_ageE &lt; 40 ~ \"Young (&lt; 40)\",\n      median_ageE &lt; 45 ~ \"Middle-aged (40-45)\",\n      TRUE ~ \"Older (45+)\"\n    )\n  )\n\nggplot(county_faceted) +\n  aes(x = total_popE, y = median_incomeE) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~age_category) +\n  labs(\n    title = \"Population-Income Relationship by Age Profile\",\n    x = \"Total Population\",\n    y = \"Median Income ($)\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(labels = comma) +\n  scale_y_continuous(labels = dollar)\n\n\n\n\n\n\n\n\nQuestion: Do the relationships between population and income differ by age profile? Yes\nYour Task: Create a visualization using income categories and multiple aesthetic mappings.\nRequirements:\n\nCreate income categories: “Low” (&lt;$50k), “Middle” ($50k-$80k), “High” (&gt;$80k)\nMake a scatter plot with population (x) vs median age (y) - Color points by income category\nSize points by the margin of error for income (median_incomeM)\nUse the “Set2” color palette: scale_color_brewer(palette = \"Set2\") **note: you’ll need to load the RColorBrewer package for this`\nFacet by income category using facet_wrap()\nUse theme_bw() theme\n\n\n# Create income categories\ncounty_income_plot &lt;- county_data %&gt;%\n  mutate(\n    income_cat = case_when(\n      median_incomeE &lt; 50000 ~ \"Low (&lt;$50K)\",\n      median_incomeE &lt; 80000 ~ \"Middle ($50K–$80K)\",\n      TRUE ~ \"High (&gt;$80K)\"\n    )\n  )\n\n# Scatter plot\nggplot(county_income_plot) +\n  aes(\n    x = total_popE,\n    y = median_ageE,\n    color = income_cat,\n    size = median_incomeM\n  ) +\n  geom_point(alpha = 0.7) +\n  scale_color_brewer(palette = \"Set2\", name = \"Income Category\") +\n  scale_size_continuous(name = \"Income MOE\") +\n  labs(\n    title = \"Population vs Median Age by Income Category\",\n    x = \"Total Population\",\n    y = \"Median Age\"\n  ) +\n  facet_wrap(~ income_cat) +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n  scale_x_continuous(labels = scales::comma)\n\n&lt;ScaleContinuousPosition&gt;\n Range:  \n Limits:    0 --    1"
  },
  {
    "objectID": "labs/lab1/week-03/script/week3_lab_exercise.html#exercise-5-data-joins-and-integration",
    "href": "labs/lab1/week-03/script/week3_lab_exercise.html#exercise-5-data-joins-and-integration",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Exercise 5: Data Joins and Integration",
    "text": "Exercise 5: Data Joins and Integration\n\n5.1 Get Additional Census Data\nYour Task: Load educational attainment data and join it with our existing data.\n\n# Get educational attainment data\neducation_data &lt;- get_acs(\n  geography = \"county\",\n  variables = c(\n    total_25plus = \"B15003_001\",    # Total population 25 years and over\n    bachelor_plus = \"B15003_022\"    # Bachelor's degree or higher\n  ),\n  state = state_choice,\n  year = 2022,\n  output = \"wide\"\n) %&gt;%\n  mutate(\n    pct_college = (bachelor_plusE / total_25plusE) * 100,\n    county_name = str_remove(NAME, paste0(\", \", state_choice))\n  ) %&gt;%\n  select(GEOID, county_name, pct_college)\n\n# Check the data\nhead(education_data)\n\n# A tibble: 6 × 3\n  GEOID county_name                    pct_college\n  &lt;chr&gt; &lt;chr&gt;                                &lt;dbl&gt;\n1 42001 Adams County, Pennsylvania           13.9 \n2 42003 Allegheny County, Pennsylvania       25.4 \n3 42005 Armstrong County, Pennsylvania       12.7 \n4 42007 Beaver County, Pennsylvania          18.3 \n5 42009 Bedford County, Pennsylvania          9.73\n6 42011 Berks County, Pennsylvania           17.2 \n\n\n\n\n5.2 Join the Datasets\nYour Task: Join the education data with our main county dataset.\n\n# Perform the join\ncombined_data &lt;- county_data %&gt;%\n  left_join(education_data, by = \"GEOID\")\n\n# Check the join worked\ncat(\"Original data rows:\", nrow(county_data), \"\\n\")\n\nOriginal data rows: 67 \n\ncat(\"Combined data rows:\", nrow(combined_data), \"\\n\")\n\nCombined data rows: 67 \n\ncat(\"Missing education data:\", sum(is.na(combined_data$pct_college)), \"\\n\")\n\nMissing education data: 0 \n\n# View the combined data\nhead(combined_data)\n\n# A tibble: 6 × 11\n  GEOID NAME     total_popE total_popM median_incomeE median_incomeM median_ageE\n  &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt;\n1 42001 Adams C…     104604         NA          78975           3334        43.8\n2 42003 Alleghe…    1245310         NA          72537            869        40.6\n3 42005 Armstro…      65538         NA          61011           2202        47  \n4 42007 Beaver …     167629         NA          67194           1531        44.9\n5 42009 Bedford…      47613         NA          58337           2606        47.3\n6 42011 Berks C…     428483         NA          74617           1191        39.9\n# ℹ 4 more variables: median_ageM &lt;dbl&gt;, county_name.x &lt;chr&gt;,\n#   county_name.y &lt;chr&gt;, pct_college &lt;dbl&gt;\n\n\n\n\n5.3 Analyze the New Relationship\nYour Task: Explore the relationship between education and income.\n\n# Education vs Income scatter plot\nggplot(combined_data) +\n  aes(x = pct_college, y = median_incomeE) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  labs(\n    title = \"Education vs Income Across Counties\",\n    x = \"Percent with Bachelor's Degree or Higher\",\n    y = \"Median Household Income ($)\"\n  ) +\n  theme_minimal() +\n  scale_y_continuous(labels = dollar)\n\n\n\n\n\n\n\n# Calculate correlation\nedu_income_cor &lt;- cor(combined_data$pct_college, combined_data$median_incomeE, use = \"complete.obs\")\nprint(paste(\"Education-Income Correlation:\", round(edu_income_cor, 3)))\n\n[1] \"Education-Income Correlation: 0.811\"\n\n\n\n\n5.4 Get Housing Data and Triple Join\nYour Task: Add housing cost data to create a three-way analysis.\n\n# Get housing cost data\nhousing_data &lt;- get_acs(\n  geography = \"county\",\n  variables = c(\n    median_rent = \"B25058_001\",     # Median contract rent\n    median_home_value = \"B25077_001\" # Median value of owner-occupied units\n  ),\n  state = state_choice,\n  year = 2022,\n  output = \"wide\"\n) %&gt;%\n  select(GEOID, median_rent = median_rentE, median_home_value = median_home_valueE)\n\n# Join all three datasets\nfull_data &lt;- combined_data %&gt;%\n  left_join(housing_data, by = \"GEOID\")\n\n# Create a housing affordability measure\nfull_data &lt;- full_data %&gt;%\n  mutate(\n    rent_to_income = (median_rent * 12) / median_incomeE * 100,\n    income_category = case_when(\n      median_incomeE &lt; 50000 ~ \"Low Income\",\n      median_incomeE &lt; 80000 ~ \"Middle Income\",\n      TRUE ~ \"High Income\"\n    )\n  )\nhead(full_data)\n\n# A tibble: 6 × 15\n  GEOID NAME     total_popE total_popM median_incomeE median_incomeM median_ageE\n  &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt;\n1 42001 Adams C…     104604         NA          78975           3334        43.8\n2 42003 Alleghe…    1245310         NA          72537            869        40.6\n3 42005 Armstro…      65538         NA          61011           2202        47  \n4 42007 Beaver …     167629         NA          67194           1531        44.9\n5 42009 Bedford…      47613         NA          58337           2606        47.3\n6 42011 Berks C…     428483         NA          74617           1191        39.9\n# ℹ 8 more variables: median_ageM &lt;dbl&gt;, county_name.x &lt;chr&gt;,\n#   county_name.y &lt;chr&gt;, pct_college &lt;dbl&gt;, median_rent &lt;dbl&gt;,\n#   median_home_value &lt;dbl&gt;, rent_to_income &lt;dbl&gt;, income_category &lt;chr&gt;\n\n\n\n\n5.5 Advanced Multi-Variable Analysis\nYour Task: Create a comprehensive visualization showing multiple relationships.\n\n# Complex multi-variable plot\nggplot(full_data) +\n  aes(x = pct_college, y = rent_to_income, \n      color = income_category, size = total_popE) +\n  geom_point(alpha = 0.7) +\n  labs(\n    title = \"Education, Housing Affordability, and Income Patterns\",\n    subtitle = \"Larger points = larger population\",\n    x = \"Percent with Bachelor's Degree or Higher\",\n    y = \"Annual Rent as % of Median Income\",\n    color = \"Income Category\",\n    size = \"Population\"\n  ) +\n  theme_minimal() +\n  guides(size = guide_legend(override.aes = list(alpha = 1)))"
  },
  {
    "objectID": "labs/lab1/week-03/script/week3_lab_exercise.html#exercise-6-publication-ready-visualization",
    "href": "labs/lab1/week-03/script/week3_lab_exercise.html#exercise-6-publication-ready-visualization",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Exercise 6: Publication-Ready Visualization",
    "text": "Exercise 6: Publication-Ready Visualization\n\n6.1 Create a Policy-Focused Visualization\nYour Task: Combine multiple visualizations to tell a more complete story about county characteristics.\n\n# Create a multi-panel figure\nlibrary(patchwork)  # For combining plots\n\n# Plot 1: Income distribution\np1 &lt;- ggplot(full_data) +\n  aes(x = median_incomeE) +\n  geom_histogram(bins = 15, fill = \"steelblue\", alpha = 0.7) +\n  labs(title = \"A) Income Distribution\", \n       x = \"Median Income ($)\", y = \"Counties\") +\n  scale_x_continuous(labels = dollar) +\n  theme_minimal()\n\n# Plot 2: Education vs Income\np2 &lt;- ggplot(full_data) +\n  aes(x = pct_college, y = median_incomeE) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"B) Education vs Income\",\n       x = \"% College Educated\", y = \"Median Income ($)\") +\n  scale_y_continuous(labels = dollar) +\n  theme_minimal()\n\n# Plot 3: Housing affordability by income category\np3 &lt;- ggplot(full_data) +\n  aes(x = income_category, y = rent_to_income, fill = income_category) +\n  geom_boxplot() +\n  labs(title = \"C) Housing Affordability by Income\",\n       x = \"Income Category\", y = \"Rent as % of Income\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n# Plot 4: Data reliability by population\np4 &lt;- ggplot(\n  county_data %&gt;%\n    mutate(income_moe_pct = (median_incomeM / median_incomeE) * 100)\n) +\n  aes(x = total_popE, y = income_moe_pct) +\n  geom_point(alpha = 0.7) +\n  geom_hline(yintercept = 10, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"D) Data Reliability\",\n       x = \"Population\", y = \"MOE (%)\") +\n  scale_x_continuous(labels = comma) +\n  theme_minimal()\n\n\n# Combine all plots\ncombined_plot &lt;- (p1 | p2) / (p3 | p4)\ncombined_plot + plot_annotation(\n  title = \"Pennsylvania County Analysis: Income, Education, and Housing Patterns\",\n  caption = \"Source: American Community Survey 2018-2022\"\n)"
  },
  {
    "objectID": "labs/lab1/week-03/script/week3_lab_exercise.html#exercise-7-ethical-data-communication---implementing-research-recommendations",
    "href": "labs/lab1/week-03/script/week3_lab_exercise.html#exercise-7-ethical-data-communication---implementing-research-recommendations",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Exercise 7: Ethical Data Communication - Implementing Research Recommendations",
    "text": "Exercise 7: Ethical Data Communication - Implementing Research Recommendations\nBackground: Research by Jurjevich et al. (2018) found that only 27% of planners warn users about unreliable ACS data, violating AICP ethical standards. In this exercise, you’ll practice the five research-based guidelines for ethical ACS data communication.\n\n7.1 Create Professional Data Tables with Uncertainty\nYour Task: Follow the Jurjevich et al. guidelines to create an ethical data presentation.\n\n# Get comprehensive data for ethical analysis\nethical_demo_data &lt;- get_acs(\n  geography = \"county\",\n  variables = c(\n    median_income = \"B19013_001\",   # Median household income\n    total_25plus = \"B15003_001\",    # Total population 25 years and over\n    bachelor_plus = \"B15003_022\",   # Bachelor's degree or higher\n    total_pop = \"B01003_001\"        # Total population\n  ),\n  state = state_choice,\n  year = 2022,\n  output = \"wide\"\n) %&gt;%\n  mutate(\n    # Calculate derived statistics\n    pct_college = (bachelor_plusE / total_25plusE) * 100,\n    \n    # Calculate MOE for percentage using error propagation\n    pct_college_moe = pct_college * sqrt((bachelor_plusM/bachelor_plusE)^2 + (total_25plusM/total_25plusE)^2),\n    \n    # Calculate coefficient of variation for all key variables\n    income_cv = (median_incomeM / median_incomeE) * 100,\n    education_cv = (pct_college_moe / pct_college) * 100,\n    \n    # Create reliability categories based on CV\n    income_reliability = case_when(\n      income_cv &lt; 12 ~ \"High\",\n      income_cv &lt;= 40 ~ \"Moderate\", \n      TRUE ~ \"Low\"\n    ),\n    \n    education_reliability = case_when(\n      education_cv &lt; 12 ~ \"High\",\n      education_cv &lt;= 40 ~ \"Moderate\",\n      TRUE ~ \"Low\"\n    ),\n    \n    # Create color coding for reliability\n    income_color = case_when(\n      income_reliability == \"High\" ~ \"🟢\",\n      income_reliability == \"Moderate\" ~ \"🟡\",\n      TRUE ~ \"🔴\"\n    ),\n    \n    education_color = case_when(\n      education_reliability == \"High\" ~ \"🟢\",\n      education_reliability == \"Moderate\" ~ \"🟡\", \n      TRUE ~ \"🔴\"\n    ),\n    \n    # Clean county names\n    county_name = str_remove(NAME, paste0(\", \", state_choice))\n  )\n\n# Create ethical data table focusing on least reliable estimates\nethical_data_table &lt;- ethical_demo_data %&gt;%\n  select(county_name, median_incomeE, median_incomeM, income_cv, income_color,\n         pct_college, pct_college_moe, education_cv, education_color) %&gt;%\n  arrange(desc(income_cv)) %&gt;%  # Show least reliable first\n  slice_head(n = 10)\n\n# Create professional table following guidelines\nlibrary(knitr)\nlibrary(kableExtra)\n\nethical_data_table %&gt;%\n  select(county_name, median_incomeE, median_incomeM, income_cv, income_color) %&gt;%\n  kable(\n    col.names = c(\"County\", \"Median Income\", \"Margin of Error\", \n                  \"CV (%)\", \"Reliability\"),\n    caption = \"Pennsylvania Counties: Median Household Income with Statistical Uncertainty\",\n    format.args = list(big.mark = \",\")\n  ) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %&gt;%\n  footnote(\n    general = c(\"Coefficient of Variation (CV) indicates reliability:\",\n                \"🟢 High reliability (CV &lt; 12%)\",\n                \"🟡 Moderate reliability (CV 12-40%)\", \n                \"🔴 Low reliability (CV &gt; 40%)\",\n                \"Following Jurjevich et al. (2018) research recommendations\",\n                \"Source: American Community Survey 2018-2022 5-Year Estimates\"),\n    general_title = \"Notes:\"\n  )\n\n\nPennsylvania Counties: Median Household Income with Statistical Uncertainty\n\n\nCounty\nMedian Income\nMargin of Error\nCV (%)\nReliability\n\n\n\n\nForest County, Pennsylvania\n46,188\n4,612\n9.985278\n🟢 |\n\n\nSullivan County, Pennsylvania\n62,910\n5,821\n9.252901\n🟢 |\n\n\nUnion County, Pennsylvania\n64,914\n4,753\n7.321995\n🟢 |\n\n\nMontour County, Pennsylvania\n72,626\n5,146\n7.085617\n🟢 |\n\n\nElk County, Pennsylvania\n61,672\n4,091\n6.633480\n🟢 |\n\n\nGreene County, Pennsylvania\n66,283\n4,247\n6.407374\n🟢 |\n\n\nCameron County, Pennsylvania\n46,186\n2,605\n5.640237\n🟢 |\n\n\nSnyder County, Pennsylvania\n65,914\n3,666\n5.561793\n🟢 |\n\n\nCarbon County, Pennsylvania\n64,538\n3,424\n5.305402\n🟢 |\n\n\nWarren County, Pennsylvania\n57,925\n3,005\n5.187743\n🟢 |\n\n\n\nNotes:\n\n\n\n\n\n\n Coefficient of Variation (CV) indicates reliability:\n\n\n\n\n\n\n 🟢 High reliability (CV &lt; 12%)\n\n\n\n\n\n\n 🟡 Moderate reliability (CV 12-40%)\n\n\n\n\n\n\n 🔴 Low reliability (CV &gt; 40%)\n\n\n\n\n\n\n Following Jurjevich et al. (2018) research recommendations\n\n\n\n\n\n\n Source: American Community Survey 2018-2022 5-Year Estimates\n\n\n\n\n\n\n\n\n\n\n\n\n7.3 Now try Census Tracts\n\n# Get census tract poverty data for Philadelphia\nphilly_poverty &lt;- get_acs(\n    geography = \"tract\",\n    variables = c(\n      poverty_pop = \"B17001_001\",     \n      poverty_below = \"B17001_002\"    \n    ),\n    state = \"PA\",\n    county = \"101\",\n    year = 2022,\n    output = \"wide\"\n  ) %&gt;%\n  filter(poverty_popE &gt; 0) %&gt;%  # Remove tracts with no poverty data\n  mutate(\n    # Calculate poverty rate and its MOE\n    poverty_rate = (poverty_belowE / poverty_popE) * 100,\n    \n    # MOE for derived percentage using error propagation\n    poverty_rate_moe = poverty_rate * sqrt((poverty_belowM/poverty_belowE)^2 + (poverty_popM/poverty_popE)^2),\n    \n    # Coefficient of variation\n    poverty_cv = (poverty_rate_moe / poverty_rate) * 100,\n    \n    # Reliability assessment\n    reliability = case_when(\n      poverty_cv &lt; 12 ~ \"High\",\n      poverty_cv &lt;= 40 ~ \"Moderate\",\n      poverty_cv &lt;= 75 ~ \"Low\",\n      TRUE ~ \"Very Low\"\n    ),\n    \n    # Color coding\n    reliability_color = case_when(\n      reliability == \"High\" ~ \"🟢\",\n      reliability == \"Moderate\" ~ \"🟡\",\n      reliability == \"Low\" ~ \"🟠\",\n      TRUE ~ \"🔴\"\n    ),\n    \n    # Population size categories\n    pop_category = case_when(\n      poverty_popE &lt; 500 ~ \"Very Small (&lt;500)\",\n      poverty_popE &lt; 1000 ~ \"Small (500-1000)\",\n      poverty_popE &lt; 1500 ~ \"Medium (1000-1500)\",\n      TRUE ~ \"Large (1500+)\"\n    )\n  )\n\n# Check the data quality crisis at tracts\nreliability_summary &lt;- philly_poverty %&gt;%\n  count(reliability) %&gt;%\n  mutate(\n    percentage = round(n / sum(n) * 100, 1),\n    total_bg = sum(n)\n  )\n\nprint(\"Philadelphia Census Tract Poverty Data Reliability:\")\n\n[1] \"Philadelphia Census Tract Poverty Data Reliability:\"\n\nreliability_summary %&gt;%\n  kable(\n    col.names = c(\"Data Quality\", \"Number of Tracts\", \"Percentage\", \"Total\"),\n    caption = \"The Data Quality Crisis: Philadelphia Census Tract Poverty Estimates\"\n  ) %&gt;%\n  kable_styling()\n\n\nThe Data Quality Crisis: Philadelphia Census Tract Poverty Estimates\n\n\nData Quality\nNumber of Tracts\nPercentage\nTotal\n\n\n\n\nLow\n295\n75.8\n389\n\n\nModerate\n53\n13.6\n389\n\n\nVery Low\n41\n10.5\n389\n\n\n\n\n\n\n# Show the most problematic estimates (following Guideline 3: provide context)\nworst_estimates &lt;- philly_poverty %&gt;%\n  filter(reliability %in% c(\"Low\", \"Very Low\")) %&gt;%\n  arrange(desc(poverty_cv)) %&gt;%\n  slice_head(n = 10)\n\nworst_estimates %&gt;%\n  select(GEOID, poverty_rate, poverty_rate_moe, poverty_cv, reliability_color, poverty_popE) %&gt;%\n  kable(\n    col.names = c(\"Tract\", \"Poverty Rate (%)\", \"MOE\", \"CV (%)\", \"Quality\", \"Pop Size\"),\n    caption = \"Guideline 3: Tracts with Least Reliable Poverty Estimates\",\n    digits = c(0, 1, 1, 1, 0, 0)\n  ) %&gt;%\n  kable_styling() %&gt;%\n  footnote(\n    general = c(\"These estimates should NOT be used for policy decisions\",\n                \"CV &gt; 75% indicates very low reliability\",\n                \"Recommend aggregation or alternative data sources\")\n  )\n\n\nGuideline 3: Tracts with Least Reliable Poverty Estimates\n\n\nTract\nPoverty Rate (%)\nMOE\nCV (%)\nQuality\nPop Size\n\n\n\n\n42101989100\n15.8\n45.2\n286.1\n🔴 |\n38|\n\n\n42101000101\n0.7\n1.1\n157.9\n🔴 |\n1947|\n\n\n42101980200\n37.9\n45.2\n119.4\n🔴 |\n66|\n\n\n42101023100\n3.8\n4.5\n119.4\n🔴 |\n1573|\n\n\n42101025600\n1.7\n2.0\n114.2\n🔴 |\n2642|\n\n\n42101014202\n1.7\n1.8\n107.0\n🔴 |\n2273|\n\n\n42101000403\n6.6\n6.7\n101.8\n🔴 |\n1047|\n\n\n42101026100\n4.7\n4.4\n95.0\n🔴 |\n2842|\n\n\n42101036502\n4.9\n4.7\n94.9\n🔴 |\n4284|\n\n\n42101032000\n21.8\n20.6\n94.8\n🔴 |\n7873|\n\n\n\nNote: \n\n\n\n\n\n\n\n These estimates should NOT be used for policy decisions\n\n\n\n\n\n\n\n CV &gt; 75% indicates very low reliability\n\n\n\n\n\n\n\n Recommend aggregation or alternative data sources"
  },
  {
    "objectID": "labs/lab1/week-03/script/week3_lab_exercise.html#key-references-and-acknowledgments",
    "href": "labs/lab1/week-03/script/week3_lab_exercise.html#key-references-and-acknowledgments",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Key References and Acknowledgments",
    "text": "Key References and Acknowledgments\nJurjevich, J. R., Griffin, A. L., Spielman, S. E., Folch, D. C., Merrick, M., & Nagle, N. N. (2018). Navigating statistical uncertainty: How urban and regional planners understand and work with American community survey (ACS) data for guiding policy. Journal of the American Planning Association, 84(2), 112-126.\nWalker, K. (2023). Analyzing US Census Data: Methods, Maps, and Models in R. Available at: https://walker-data.com/census-r/\nAI Acknowledgments: This lab was developed with coding assistance from Claude AI. I have run, reviewed, and edited the final version. Any remaining errors are my own."
  },
  {
    "objectID": "Assignments /Assignment_1/assignment1_template (2).html",
    "href": "Assignments /Assignment_1/assignment1_template (2).html",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the [Your State] Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.\n\n\n\n\nApply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders\n\n\n\n\nSubmit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Assignments” menu."
  },
  {
    "objectID": "Assignments /Assignment_1/assignment1_template (2).html#scenario",
    "href": "Assignments /Assignment_1/assignment1_template (2).html#scenario",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the [Your State] Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues."
  },
  {
    "objectID": "Assignments /Assignment_1/assignment1_template (2).html#learning-objectives",
    "href": "Assignments /Assignment_1/assignment1_template (2).html#learning-objectives",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Apply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders"
  },
  {
    "objectID": "Assignments /Assignment_1/assignment1_template (2).html#submission-instructions",
    "href": "Assignments /Assignment_1/assignment1_template (2).html#submission-instructions",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Submit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Assignments” menu."
  },
  {
    "objectID": "Assignments /Assignment_1/assignment1_template (2).html#data-retrieval",
    "href": "Assignments /Assignment_1/assignment1_template (2).html#data-retrieval",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.1 Data Retrieval",
    "text": "2.1 Data Retrieval\nYour Task: Use get_acs() to retrieve county-level data for your chosen state.\nRequirements: - Geography: county level - Variables: median household income (B19013_001) and total population (B01003_001)\n- Year: 2022 - Survey: acs5 - Output format: wide\nHint: Remember to give your variables descriptive names using the variables = c(name = \"code\") syntax.\n\n# Write your get_acs() code here\n\n# Clean the county names to remove state name and \"County\" \n# Hint: use mutate() with str_remove()\n\n# Display the first few rows"
  },
  {
    "objectID": "Assignments /Assignment_1/assignment1_template (2).html#data-quality-assessment",
    "href": "Assignments /Assignment_1/assignment1_template (2).html#data-quality-assessment",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.2 Data Quality Assessment",
    "text": "2.2 Data Quality Assessment\nYour Task: Calculate margin of error percentages and create reliability categories.\nRequirements: - Calculate MOE percentage: (margin of error / estimate) * 100 - Create reliability categories: - High Confidence: MOE &lt; 5% - Moderate Confidence: MOE 5-10%\n- Low Confidence: MOE &gt; 10% - Create a flag for unreliable estimates (MOE &gt; 10%)\nHint: Use mutate() with case_when() for the categories.\n\n# Calculate MOE percentage and reliability categories using mutate()\n\n# Create a summary showing count of counties in each reliability category\n# Hint: use count() and mutate() to add percentages"
  },
  {
    "objectID": "Assignments /Assignment_1/assignment1_template (2).html#high-uncertainty-counties",
    "href": "Assignments /Assignment_1/assignment1_template (2).html#high-uncertainty-counties",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.3 High Uncertainty Counties",
    "text": "2.3 High Uncertainty Counties\nYour Task: Identify the 5 counties with the highest MOE percentages.\nRequirements: - Sort by MOE percentage (highest first) - Select the top 5 counties - Display: county name, median income, margin of error, MOE percentage, reliability category - Format as a professional table using kable()\nHint: Use arrange(), slice(), and select() functions.\n\n# Create table of top 5 counties by MOE percentage\n\n# Format as table with kable() - include appropriate column names and caption\n\nData Quality Commentary:\n[Write 2-3 sentences explaining what these results mean for algorithmic decision-making. Consider: Which counties might be poorly served by algorithms that rely on this income data? What factors might contribute to higher uncertainty?]"
  },
  {
    "objectID": "Assignments /Assignment_1/assignment1_template (2).html#focus-area-selection",
    "href": "Assignments /Assignment_1/assignment1_template (2).html#focus-area-selection",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.1 Focus Area Selection",
    "text": "3.1 Focus Area Selection\nYour Task: Select 2-3 counties from your reliability analysis for detailed tract-level study.\nStrategy: Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.\n\n# Use filter() to select 2-3 counties from your county_reliability data\n# Store the selected counties in a variable called selected_counties\n\n# Display the selected counties with their key characteristics\n# Show: county name, median income, MOE percentage, reliability category\n\nComment on the output: [write something :)]"
  },
  {
    "objectID": "Assignments /Assignment_1/assignment1_template (2).html#tract-level-demographics",
    "href": "Assignments /Assignment_1/assignment1_template (2).html#tract-level-demographics",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.2 Tract-Level Demographics",
    "text": "3.2 Tract-Level Demographics\nYour Task: Get demographic data for census tracts in your selected counties.\nRequirements: - Geography: tract level - Variables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001) - Use the same state and year as before - Output format: wide - Challenge: You’ll need county codes, not names. Look at the GEOID patterns in your county data for hints.\n\n# Define your race/ethnicity variables with descriptive names\n\n# Use get_acs() to retrieve tract-level data\n# Hint: You may need to specify county codes in the county parameter\n\n# Calculate percentage of each group using mutate()\n# Create percentages for white, Black, and Hispanic populations\n\n# Add readable tract and county name columns using str_extract() or similar"
  },
  {
    "objectID": "Assignments /Assignment_1/assignment1_template (2).html#demographic-analysis",
    "href": "Assignments /Assignment_1/assignment1_template (2).html#demographic-analysis",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.3 Demographic Analysis",
    "text": "3.3 Demographic Analysis\nYour Task: Analyze the demographic patterns in your selected areas.\n\n# Find the tract with the highest percentage of Hispanic/Latino residents\n# Hint: use arrange() and slice() to get the top tract\n\n# Calculate average demographics by county using group_by() and summarize()\n# Show: number of tracts, average percentage for each racial/ethnic group\n\n# Create a nicely formatted table of your results using kable()"
  },
  {
    "objectID": "Assignments /Assignment_1/assignment1_template (2).html#moe-analysis-for-demographic-variables",
    "href": "Assignments /Assignment_1/assignment1_template (2).html#moe-analysis-for-demographic-variables",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "4.1 MOE Analysis for Demographic Variables",
    "text": "4.1 MOE Analysis for Demographic Variables\nYour Task: Examine margins of error for demographic variables to see if some communities have less reliable data.\nRequirements: - Calculate MOE percentages for each demographic variable - Flag tracts where any demographic variable has MOE &gt; 15% - Create summary statistics\n\n# Calculate MOE percentages for white, Black, and Hispanic variables\n# Hint: use the same formula as before (margin/estimate * 100)\n\n# Create a flag for tracts with high MOE on any demographic variable\n# Use logical operators (| for OR) in an ifelse() statement\n\n# Create summary statistics showing how many tracts have data quality issues"
  },
  {
    "objectID": "Assignments /Assignment_1/assignment1_template (2).html#pattern-analysis",
    "href": "Assignments /Assignment_1/assignment1_template (2).html#pattern-analysis",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "4.2 Pattern Analysis",
    "text": "4.2 Pattern Analysis\nYour Task: Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.\n\n# Group tracts by whether they have high MOE issues\n# Calculate average characteristics for each group:\n# - population size, demographic percentages\n\n# Use group_by() and summarize() to create this comparison\n# Create a professional table showing the patterns\n\nPattern Analysis: [Describe any patterns you observe. Do certain types of communities have less reliable data? What might explain this?]"
  },
  {
    "objectID": "Assignments /Assignment_1/assignment1_template (2).html#analysis-integration-and-professional-summary",
    "href": "Assignments /Assignment_1/assignment1_template (2).html#analysis-integration-and-professional-summary",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "5.1 Analysis Integration and Professional Summary",
    "text": "5.1 Analysis Integration and Professional Summary\nYour Task: Write an executive summary that integrates findings from all four analyses.\nExecutive Summary Requirements: 1. Overall Pattern Identification: What are the systematic patterns across all your analyses? 2. Equity Assessment: Which communities face the greatest risk of algorithmic bias based on your findings? 3. Root Cause Analysis: What underlying factors drive both data quality issues and bias risk? 4. Strategic Recommendations: What should the Department implement to address these systematic issues?\nExecutive Summary:\n[Your integrated 4-paragraph summary here]"
  },
  {
    "objectID": "Assignments /Assignment_1/assignment1_template (2).html#specific-recommendations",
    "href": "Assignments /Assignment_1/assignment1_template (2).html#specific-recommendations",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "6.3 Specific Recommendations",
    "text": "6.3 Specific Recommendations\nYour Task: Create a decision framework for algorithm implementation.\n\n# Create a summary table using your county reliability data\n# Include: county name, median income, MOE percentage, reliability category\n\n# Add a new column with algorithm recommendations using case_when():\n# - High Confidence: \"Safe for algorithmic decisions\"\n# - Moderate Confidence: \"Use with caution - monitor outcomes\"  \n# - Low Confidence: \"Requires manual review or additional data\"\n\n# Format as a professional table with kable()\n\nKey Recommendations:\nYour Task: Use your analysis results to provide specific guidance to the department.\n\nCounties suitable for immediate algorithmic implementation: [List counties with high confidence data and explain why they’re appropriate]\nCounties requiring additional oversight: [List counties with moderate confidence data and describe what kind of monitoring would be needed]\nCounties needing alternative approaches: [List counties with low confidence data and suggest specific alternatives - manual review, additional surveys, etc.]"
  },
  {
    "objectID": "Assignments /Assignment_1/assignment1_template (2).html#questions-for-further-investigation",
    "href": "Assignments /Assignment_1/assignment1_template (2).html#questions-for-further-investigation",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "Questions for Further Investigation",
    "text": "Questions for Further Investigation\n[List 2-3 questions that your analysis raised that you’d like to explore further in future assignments. Consider questions about spatial patterns, time trends, or other demographic factors.]"
  },
  {
    "objectID": "Assignments /Assignment_1/assignment1_template (2).html#submission-checklist",
    "href": "Assignments /Assignment_1/assignment1_template (2).html#submission-checklist",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "Submission Checklist",
    "text": "Submission Checklist\nBefore submitting your portfolio link on Canvas:\n\nAll code chunks run without errors\nAll “[Fill this in]” prompts have been completed\nTables are properly formatted and readable\nExecutive summary addresses all four required components\nPortfolio navigation includes this assignment\nCensus API key is properly set\nDocument renders correctly to HTML\n\nRemember: Submit your portfolio URL on Canvas, not the file itself. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/your_file_name.html"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment1 alex.html",
    "href": "Assignments /Assignment_1/Assignment1 alex.html",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the Michigan Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.\n\n\n\n\nApply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders\n\n\n\n\nSubmit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Assignments” menu."
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment1 alex.html#scenario",
    "href": "Assignments /Assignment_1/Assignment1 alex.html#scenario",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the Michigan Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues."
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment1 alex.html#learning-objectives",
    "href": "Assignments /Assignment_1/Assignment1 alex.html#learning-objectives",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Apply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment1 alex.html#submission-instructions",
    "href": "Assignments /Assignment_1/Assignment1 alex.html#submission-instructions",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Submit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Assignments” menu."
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment1 alex.html#data-retrieval",
    "href": "Assignments /Assignment_1/Assignment1 alex.html#data-retrieval",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.1 Data Retrieval",
    "text": "2.1 Data Retrieval\nYour Task: Use get_acs() to retrieve county-level data for your chosen state.\nRequirements: - Geography: county level - Variables: median household income (B19013_001) and total population (B01003_001)\n- Year: 2022 - Survey: acs5 - Output format: wide\nHint: Remember to give your variables descriptive names using the variables = c(name = \"code\") syntax.\n\n# Write your get_acs() code here\ncounty_data_2022 &lt;- get_acs(geography = \"county\", \n                         state = \"MI\",\n                         variables = c(med_household_income = \"B19013_001\", total_pop = \"B01003_001\" ),\n                         year = 2022,\n                         survey = \"acs5\",\n                         output = \"wide\")\n                         \n\n# Clean the county names to remove state name and \"County\" \ncounty_data_2022 &lt;- county_data_2022 %&gt;%\n  mutate(county_data_2022_clean = str_remove(NAME,paste0(\"County, Michigan\")))\n# Hint: use mutate() with str_remove()\n\n# Display the first few rows\nhead(county_data_2022)\n\n# A tibble: 6 × 7\n  GEOID NAME   med_household_incomeE med_household_incomeM total_popE total_popM\n  &lt;chr&gt; &lt;chr&gt;                  &lt;dbl&gt;                 &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 26001 Alcon…                 50295                  2243      10238         NA\n2 26003 Alger…                 55528                  2912       8866         NA\n3 26005 Alleg…                 75543                  2369     120189         NA\n4 26007 Alpen…                 49133                  2119      28911         NA\n5 26009 Antri…                 68850                  3115      23662         NA\n6 26011 Arena…                 53487                  2018      15031         NA\n# ℹ 1 more variable: county_data_2022_clean &lt;chr&gt;"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment1 alex.html#data-quality-assessment",
    "href": "Assignments /Assignment_1/Assignment1 alex.html#data-quality-assessment",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.2 Data Quality Assessment",
    "text": "2.2 Data Quality Assessment\nYour Task: Calculate margin of error percentages and create reliability categories.\nRequirements: - Calculate MOE percentage: (margin of error / estimate) * 100 - Create reliability categories: - High Confidence: MOE &lt; 5% - Moderate Confidence: MOE 5-10%\n- Low Confidence: MOE &gt; 10% - Create a flag for unreliable estimates (MOE &gt; 10%)\nHint: Use mutate() with case_when() for the categories.\n\n# Calculate MOE percentage and reliability categories using mutate()\nMI_county_reliablility &lt;- county_data_2022 %&gt;%\n  mutate(\n    med_income_moe_pct = (med_household_incomeM / med_household_incomeE) * 100,\n    med_income_confi = case_when(\n      med_income_moe_pct &lt; 5 ~ \"High Confidence (&lt;5%)\",\n      med_income_moe_pct &gt; 5 & med_income_moe_pct &lt;10 ~ \"Moderate Confidence (5% - 10%)\",\n      med_income_moe_pct &gt; 10  ~ \"Low Confidence (&gt;10%)\"\n    )\n  )\n# Create a summary showing count of counties in each reliability category\nMI_reability_data &lt;- MI_county_reliablility %&gt;%\n  count(med_income_confi)%&gt;%\n  mutate(percentage = round(n/sum(n)*100, 2))\n\nkable(MI_reability_data,\n      caption = \"**MI Reliability Summary**\",\n      align = c(\"l\", \"c\", \"r\"),\n      digits = 2,\n      row.names = TRUE,\n      col.names = c(\"Confidence\", \"Count\", \"Percentage\")\n)\n\n\nMI Reliability Summary\n\n\n\nConfidence\nCount\nPercentage\n\n\n\n\n1\nHigh Confidence (&lt;5%)\n56\n67.47\n\n\n2\nLow Confidence (&gt;10%)\n2\n2.41\n\n\n3\nModerate Confidence (5% - 10%)\n25\n30.12\n\n\n\n\n# Hint: use count() and mutate() to add percentages"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment1 alex.html#high-uncertainty-counties",
    "href": "Assignments /Assignment_1/Assignment1 alex.html#high-uncertainty-counties",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.3 High Uncertainty Counties",
    "text": "2.3 High Uncertainty Counties\nYour Task: Identify the 5 counties with the highest MOE percentages.\nRequirements: - Sort by MOE percentage (highest first) - Select the top 5 counties - Display: county name, median income, margin of error, MOE percentage, reliability category - Format as a professional table using kable()\nHint: Use arrange(), slice(), and select() functions.\n\n# Create table of top 5 counties by MOE percentage\ntop5_byMOE &lt;- MI_county_reliablility %&gt;% \n  arrange(desc(med_income_moe_pct))%&gt;% \n  slice(1:5)%&gt;% \n  select(county_data_2022_clean, med_household_incomeE, med_household_incomeM, med_income_moe_pct, med_income_confi) \n\nkable(top5_byMOE, \n      caption = \"**Top 5 Counties by MOE Percentage**\", \n      align = c(\"l\", \"c\", \"c\", \"c\", \"r\"),\n      digits = 2, \n      row.names = TRUE, \n      col.names = c(\"County\", \"Med. Household Income\", \"Income MOE\", \"MOE %\", \"Confidence Intervals\"))\n\n\nTop 5 Counties by MOE Percentage\n\n\n\n\n\n\n\n\n\n\n\nCounty\nMed. Household Income\nIncome MOE\nMOE %\nConfidence Intervals\n\n\n\n\n1\nKeweenaw\n55560\n7301\n13.14\nLow Confidence (&gt;10%)\n\n\n2\nSchoolcraft\n55071\n6328\n11.49\nLow Confidence (&gt;10%)\n\n\n3\nGogebic\n47913\n4766\n9.95\nModerate Confidence (5% - 10%)\n\n\n4\nOtsego\n62865\n5910\n9.40\nModerate Confidence (5% - 10%)\n\n\n5\nMontmorency\n46345\n3796\n8.19\nModerate Confidence (5% - 10%)\n\n\n\n\n# Format as table with kable() - include appropriate column names and caption\n\nData Quality Commentary:\nThese are the top 5 counties in Michigan with the highest MOE. Only Keweenaw and Schoolcraft maintain the lowest confidence intervals, probably due to being some of the smallest counties in the state by population (therefore, presumably, little regard is afforded to them and the residents)."
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment1 alex.html#focus-area-selection",
    "href": "Assignments /Assignment_1/Assignment1 alex.html#focus-area-selection",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.1 Focus Area Selection",
    "text": "3.1 Focus Area Selection\nYour Task: Select 2-3 counties from your reliability analysis for detailed tract-level study.\nStrategy: Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.\n\n# Use filter() to select 2-3 counties from your county_reliability data\n# Store the selected counties in a variable called selected_counties\nselected_counties = top5_byMOE %&gt;%\n  filter(med_household_incomeE == 55071 | med_household_incomeE == 47913)\n\n      \n# Display the selected counties with their key characteristics\n# Show: county name, median income, MOE percentage, reliability category\nselected_counties %&gt;%\n  select(county_data_2022_clean, med_household_incomeE, med_income_moe_pct, med_income_confi) %&gt;%\n  kable(\n        caption = \"**Schoolcraft and Gogebic County Income Demographics**\",\n        align = c(\"l\", \"c\", \"c\", \"r\"),\n        row.names = TRUE,\n        col.names = c(\"County Name\", \"Median Income\", \"MOE (%)\", \"Reliability Category\")\n  )\n\n\nSchoolcraft and Gogebic County Income Demographics\n\n\n\n\n\n\n\n\n\n\nCounty Name\nMedian Income\nMOE (%)\nReliability Category\n\n\n\n\n1\nSchoolcraft\n55071\n11.490621\nLow Confidence (&gt;10%)\n\n\n2\nGogebic\n47913\n9.947196\nModerate Confidence (5% - 10%)\n\n\n\n\n\nComment on the output: Despite Schoolcraft having a higher median income, the MOE surpasses the &gt;10% threshold and therefore falls into the Low Confidence category."
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment1 alex.html#tract-level-demographics",
    "href": "Assignments /Assignment_1/Assignment1 alex.html#tract-level-demographics",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.2 Tract-Level Demographics",
    "text": "3.2 Tract-Level Demographics\nYour Task: Get demographic data for census tracts in your selected counties.\nRequirements: - Geography: tract level - Variables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001) - Use the same state and year as before - Output format: wide - Challenge: You’ll need county codes, not names. Look at the GEOID patterns in your county data for hints.\n\n# Define your race/ethnicity variables with descriptive names\nrace_vars &lt;- get_acs(geography = \"tract\",\n                     survey = \"acs5\",\n                     variables = c(white = \"B03002_003\", \n                                   black = \"B03002_004\",\n                                   hisp_latinx = \"B03002_012\",\n                                   total_pop = \"B03002_001\"),\n                     year = 2022,\n                     state = \"MI\",\n                     county = c(\"153\", \"053\"), #Schoolcraft is 26153, Gogebic is 26053. \n                     output = \"wide\"\n)\n                     \n                     \n# Use get_acs() to retrieve tract-level data\n# Hint: You may need to specify county codes in the county parameter\n# Calculate percentage of each group using mutate()\n# Create percentages for white, Black, and Hispanic populations\nrace_vars_percts = race_vars %&gt;%\n  mutate(perct_white = (whiteE/total_popE) * 100,\n         perct_black = (blackE/total_popE) * 100,\n         perct_latinx = (hisp_latinxE/total_popE) * 100,\n         tract_name = str_extract(NAME, \"Census Tract \\\\d+\"),\n         county_name = str_extract(NAME, \"[A-Za-z]+ County\" )\n  )\n\n# Add readable tract and county name columns using str_extract() or similar MUTATE()& Extract()"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment1 alex.html#demographic-analysis",
    "href": "Assignments /Assignment_1/Assignment1 alex.html#demographic-analysis",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.3 Demographic Analysis",
    "text": "3.3 Demographic Analysis\nYour Task: Analyze the demographic patterns in your selected areas.\n\n# Find the tract with the highest percentage of Hispanic/Latino residents\n# Hint: use arrange() and slice() to get the top tract\nmax_latinx &lt;- race_vars_percts %&gt;%\n  arrange(desc(perct_latinx))%&gt;%\n  slice(1)\nkable(max_latinx,\n      caption = \"HELP\", \n      )\n\n\nHELP\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGEOID\nNAME\nwhiteE\nwhiteM\nblackE\nblackM\nhisp_latinxE\nhisp_latinxM\ntotal_popE\ntotal_popM\nperct_white\nperct_black\nperct_latinx\ntract_name\ncounty_name\n\n\n\n\n26053950600\nCensus Tract 9506; Gogebic County; Michigan\n2593\n183\n0\n11\n122\n50\n2817\n187\n92.04828\n0\n4.330848\nCensus Tract 9506\nGogebic County\n\n\n\n\n# Calculate average demographics by county using group_by() and summarize()\n# Show: number of tracts, average percentage for each racial/ethnic group\navg_demo &lt;- race_vars_percts %&gt;%\n  group_by(county_name) %&gt;%\n  summarize(\n    ntracts    = n(),\n    white_avg  = mean(perct_white, na.rm = TRUE),\n    black_avg  = mean(perct_black, na.rm = TRUE),\n    latinx_avg = mean(perct_latinx, na.rm = TRUE)\n  )\n# Create a nicely formatted table of your results using kable()\nkable(avg_demo,\n      caption = \"Average Demographic Per County\",\n      align = c(\"l\", \"c\", \"c\", \"c\", \"r\"),\n      col.names = c(\"County Name\", \"No. of Tracts\", \"% White\", \"% Black\", \"% LatinX\"),\n      row.names = TRUE\n)\n\n\nAverage Demographic Per County\n\n\n\n\n\n\n\n\n\n\n\nCounty Name\nNo. of Tracts\n% White\n% Black\n% LatinX\n\n\n\n\n1\nGogebic County\n7\n90.86211\n1.7049326\n1.841025\n\n\n2\nSchoolcraft County\n4\n84.84429\n0.5191899\n1.504404"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment1 alex.html#moe-analysis-for-demographic-variables",
    "href": "Assignments /Assignment_1/Assignment1 alex.html#moe-analysis-for-demographic-variables",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "4.1 MOE Analysis for Demographic Variables",
    "text": "4.1 MOE Analysis for Demographic Variables\nYour Task: Examine margins of error for demographic variables to see if some communities have less reliable data.\nRequirements: - Calculate MOE percentages for each demographic variable - Flag tracts where any demographic variable has MOE &gt; 15% - Create summary statistics\n\n# Calculate MOE percentages for white, Black, and Hispanic variables\n# Hint: use the same formula as before (margin/estimate * 100)\n# Create a flag for tracts with high MOE on any demographic variable\n# Use logical operators (| for OR) in an ifelse() statement\nmoe_gogegic_schoolcraft = race_vars_percts %&gt;%\n  mutate(\n  MOE_white = (whiteM/whiteE) * 100, \n  MOE_black = (blackM/blackE) * 100,\n  MOE_latinx = (hisp_latinxM/hisp_latinxE) * 100,\n  MOE_flag = ifelse(MOE_white &gt; 15 | MOE_black &gt; 15 |  MOE_latinx &gt; 15,\n  TRUE,\n  FALSE\n  )\n  )\n# Create summary statistics showing how many tracts have data quality issues\nmoe_summary_county &lt;- moe_gogegic_schoolcraft %&gt;%\n  group_by(county_name) %&gt;%\n  summarize(\n    total_tracts    = n(),\n    high_MOE_tracts = sum(MOE_flag, na.rm = TRUE),\n    pct_high_MOE    = round(100 * high_MOE_tracts / total_tracts, 1)\n  )\n\nkable (\n  moe_summary_county,\n  caption = \"**MOE Summary**\",\n  row.names = TRUE,\n  col.names = c(\"County\", \"Total Tracts\", \"High MOE Tracts\", \"Percent High MOE(%)\"),\n  align = c(\"l\",\"c\",\"c\",\"r\")\n)\n\n\nMOE Summary\n\n\n\n\n\n\n\n\n\n\nCounty\nTotal Tracts\nHigh MOE Tracts\nPercent High MOE(%)\n\n\n\n\n1\nGogebic County\n7\n7\n100\n\n\n2\nSchoolcraft County\n4\n4\n100"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment1 alex.html#pattern-analysis",
    "href": "Assignments /Assignment_1/Assignment1 alex.html#pattern-analysis",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "4.2 Pattern Analysis",
    "text": "4.2 Pattern Analysis\nYour Task: Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.\n\n# Group tracts by whether they have high MOE issues\n# Calculate average characteristics for each group:\n# - population size, demographic percentages\nmoe_patterns &lt;- moe_gogegic_schoolcraft %&gt;%\n  group_by(county_name, MOE_flag) %&gt;%\n  summarize(\n    avg_pop     = mean(total_popE, na.rm = TRUE),\n    avg_white   = mean(perct_white, na.rm = TRUE),\n    avg_black   = mean(perct_black, na.rm = TRUE),\n    avg_latinx  = mean(perct_latinx, na.rm = TRUE),\n    n_tracts    = n()\n  )\n\nkable(moe_patterns,\n      caption = \"**Comparison of High-MOE vs Reliable Tracts**\",\n      align = c(\"l\", \"c\", \"c\", \"c\",\"c\",\"c\",\"r\"),\n      col.names = c(\"County\", \"Flag Status\", \"Population Average\", \"% White Avg\", \"% Black Avg\", \"% LatinX\", \"Tracts Quantity\"),\n      digits = 2\n)\n\n\nComparison of High-MOE vs Reliable Tracts\n\n\n\n\n\n\n\n\n\n\n\nCounty\nFlag Status\nPopulation Average\n% White Avg\n% Black Avg\n% LatinX\nTracts Quantity\n\n\n\n\nGogebic County\nTRUE\n2085.29\n90.86\n1.70\n1.84\n7\n\n\nSchoolcraft County\nTRUE\n2015.50\n84.84\n0.52\n1.50\n4\n\n\n\n\n\nPattern Analysis: Both counties have a population between 2000 - 3000, but Gogebic County has four more tracts available than Schoolcraft. It doesn’t seem to matter much because in previous evaluations, demographic results for white estimated, black estimated, and latinx estimated were 0, with an MOE of 11. The sample size is just too small. I am sincerely not surprised that both of these counties are flagged for having high MOEs."
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment1 alex.html#analysis-integration-and-professional-summary",
    "href": "Assignments /Assignment_1/Assignment1 alex.html#analysis-integration-and-professional-summary",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "5.1 Analysis Integration and Professional Summary",
    "text": "5.1 Analysis Integration and Professional Summary\nYour Task: Write an executive summary that integrates findings from all four analyses.\nExecutive Summary Requirements: 1. Overall Pattern Identification: What are the systematic patterns across all your analyses? 2. Equity Assessment: Which communities face the greatest risk of algorithmic bias based on your findings? 3. Root Cause Analysis: What underlying factors drive both data quality issues and bias risk? 4. Strategic Recommendations: What should the Department implement to address these systematic issues?\nExecutive Summary:\nSome systematic patterns across all analyses is that the minority population is immensely small compared to the overwhelming majority of 90% white. The MOE has been consistently higher, which has led to some tracts within both counties to have a population estimate of 0, indicating a small sample size.\nBoth the black and LatinX communities face algorithmic biased simply because their population is so small, meaning there is likely to be a greater margin of error."
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment1 alex.html#specific-recommendations",
    "href": "Assignments /Assignment_1/Assignment1 alex.html#specific-recommendations",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "6.3 Specific Recommendations",
    "text": "6.3 Specific Recommendations\nYour Task: Create a decision framework for algorithm implementation.\n\n# Create a summary table using your county reliability data\n# Include: county name, median income, MOE percentage, reliability category\nsum_table = selected_counties %&gt;%\n  select(\n    county_name = county_data_2022_clean,\n    med_inc = med_household_incomeE,\n    moe_pct = med_income_moe_pct,\n    conf_interval = med_income_confi\n  ) %&gt;%\n  \n\n  mutate(\n    recs = case_when(\n      moe_pct &lt; 5 ~ \"Safe for algorithmic decisions\",\n      moe_pct &lt; 10 ~ \"Use with caution - monitor outcomes\",\n      TRUE ~ \"Requires manual review or additional data\"\n    )\n  )\n# Add a new column with algorithm recommendations using case_when():\n# - High Confidence: \"Safe for algorithmic decisions\"\n# - Moderate Confidence: \"Use with caution - monitor outcomes\"  \n# - Low Confidence: \"Requires manual review or additional data\"\nkable(sum_table,\n      caption = \"**Algorithm Recommendations**\",\n      col.names = c(\"County\", \"Median Income\", \"MOE (%)\", \"Confidence Interval\", \"Recommendation\"),\n      digits = 2,\n      align = c(\"l\", \"c\", \"c\", \"c\", \"r\"),\n      \n)\n\n\nAlgorithm Recommendations\n\n\n\n\n\n\n\n\n\nCounty\nMedian Income\nMOE (%)\nConfidence Interval\nRecommendation\n\n\n\n\nSchoolcraft\n55071\n11.49\nLow Confidence (&gt;10%)\nRequires manual review or additional data\n\n\nGogebic\n47913\n9.95\nModerate Confidence (5% - 10%)\nUse with caution - monitor outcomes\n\n\n\n\n# Format as a professional table with kable()\n\nKey Recommendations:\nYour Task: Use your analysis results to provide specific guidance to the department.\n\nCounties suitable for immediate algorithmic implementation: [List counties with high confidence data and explain why they’re appropriate]\nCounties requiring additional oversight: [List counties with moderate confidence data and describe what kind of monitoring would be needed]\nCounties needing alternative approaches: [List counties with low confidence data and suggest specific alternatives - manual review, additional surveys, etc.]"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment1 alex.html#questions-for-further-investigation",
    "href": "Assignments /Assignment_1/Assignment1 alex.html#questions-for-further-investigation",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "Questions for Further Investigation",
    "text": "Questions for Further Investigation\n[List 2-3 questions that your analysis raised that you’d like to explore further in future assignments. Consider questions about spatial patterns, time trends, or other demographic factors.]"
  },
  {
    "objectID": "Assignments /Assignment_1/Assignment1 alex.html#submission-checklist",
    "href": "Assignments /Assignment_1/Assignment1 alex.html#submission-checklist",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "Submission Checklist",
    "text": "Submission Checklist\nBefore submitting your portfolio link on Canvas:\n\nAll code chunks run without errors\nAll “[Fill this in]” prompts have been completed\nTables are properly formatted and readable\nExecutive summary addresses all four required components\nPortfolio navigation includes this assignment\nCensus API key is properly set\nDocument renders correctly to HTML\n\nRemember: Submit your portfolio URL on Canvas, not the file itself. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/your_file_name.html"
  },
  {
    "objectID": "weekly-notes/week-03-notes.html",
    "href": "weekly-notes/week-03-notes.html",
    "title": "Week 3 Notes",
    "section": "",
    "text": "[List main concepts from lecture] – Anscombe’s Quartet and the limits of summary statistics – Visualization in policy context – Connection to algorithmic bias and data ethics – ggplot2 fundamentals – Aesthetic mappings and geoms – Live demonstration – EDA workflow and principles – Understanding distributions and relationships – Critical focus: Data quality and uncertainty\n[Technical skills covered] ggplot(data = your_data) + aes(x = variable1, y = variable2) + geom_something() + additional_layers()"
  },
  {
    "objectID": "weekly-notes/week-03-notes.html#key-concepts-learned",
    "href": "weekly-notes/week-03-notes.html#key-concepts-learned",
    "title": "Week 3 Notes",
    "section": "",
    "text": "[List main concepts from lecture] – Anscombe’s Quartet and the limits of summary statistics – Visualization in policy context – Connection to algorithmic bias and data ethics – ggplot2 fundamentals – Aesthetic mappings and geoms – Live demonstration – EDA workflow and principles – Understanding distributions and relationships – Critical focus: Data quality and uncertainty\n[Technical skills covered] ggplot(data = your_data) + aes(x = variable1, y = variable2) + geom_something() + additional_layers()"
  },
  {
    "objectID": "weekly-notes/week-03-notes.html#coding-techniques",
    "href": "weekly-notes/week-03-notes.html#coding-techniques",
    "title": "Week 3 Notes",
    "section": "Coding Techniques",
    "text": "Coding Techniques\n\n[New R functions or approaches]\n[Quarto features learned]"
  },
  {
    "objectID": "weekly-notes/week-03-notes.html#questions-challenges",
    "href": "weekly-notes/week-03-notes.html#questions-challenges",
    "title": "Week 3 Notes",
    "section": "Questions & Challenges",
    "text": "Questions & Challenges\n\n[What I didn’t fully understand]\n[Areas needing more practice]"
  },
  {
    "objectID": "weekly-notes/week-03-notes.html#connections-to-policy",
    "href": "weekly-notes/week-03-notes.html#connections-to-policy",
    "title": "Week 3 Notes",
    "section": "Connections to Policy",
    "text": "Connections to Policy\n\n[How this week’s content applies to real policy work] – Summary statistics can hide critical patterns – Outliers may represent important communities – Relationships aren’t always linear – Visual inspection reveals data quality issues"
  },
  {
    "objectID": "weekly-notes/week-03-notes.html#reflection",
    "href": "weekly-notes/week-03-notes.html#reflection",
    "title": "Week 3 Notes",
    "section": "Reflection",
    "text": "Reflection\n\n[What was most interesting]\n[How I’ll apply this knowledge]"
  },
  {
    "objectID": "weekly-notes/week-01-notes.html",
    "href": "weekly-notes/week-01-notes.html",
    "title": "Week 1 Notes - Course Introduction",
    "section": "",
    "text": "[List main concepts from lecture] Repository (repo): Folder containing your project files Commit: Snapshot of your work at a point in time Push: Send your changes to GitHub cloud Pull: Get latest changes from GitHub cloud\n[Technical skills covered]"
  },
  {
    "objectID": "weekly-notes/week-01-notes.html#key-concepts-learned",
    "href": "weekly-notes/week-01-notes.html#key-concepts-learned",
    "title": "Week 1 Notes - Course Introduction",
    "section": "",
    "text": "[List main concepts from lecture] Repository (repo): Folder containing your project files Commit: Snapshot of your work at a point in time Push: Send your changes to GitHub cloud Pull: Get latest changes from GitHub cloud\n[Technical skills covered]"
  },
  {
    "objectID": "weekly-notes/week-01-notes.html#coding-techniques",
    "href": "weekly-notes/week-01-notes.html#coding-techniques",
    "title": "Week 1 Notes - Course Introduction",
    "section": "Coding Techniques",
    "text": "Coding Techniques\n\n[New R functions or approaches]\n[Quarto features learned]"
  },
  {
    "objectID": "weekly-notes/week-01-notes.html#questions-challenges",
    "href": "weekly-notes/week-01-notes.html#questions-challenges",
    "title": "Week 1 Notes - Course Introduction",
    "section": "Questions & Challenges",
    "text": "Questions & Challenges\n\n[What I didn’t fully understand]\n[Areas needing more practice]"
  },
  {
    "objectID": "weekly-notes/week-01-notes.html#connections-to-policy",
    "href": "weekly-notes/week-01-notes.html#connections-to-policy",
    "title": "Week 1 Notes - Course Introduction",
    "section": "Connections to Policy",
    "text": "Connections to Policy\n\n[How this week’s content applies to real policy work]"
  },
  {
    "objectID": "weekly-notes/week-01-notes.html#reflection",
    "href": "weekly-notes/week-01-notes.html#reflection",
    "title": "Week 1 Notes - Course Introduction",
    "section": "Reflection",
    "text": "Reflection\n\n[What was most interesting]\n[How I’ll apply this knowledge]"
  }
]